{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import struct\n",
    "from typing import Tuple\n",
    "from bitarray import bitarray\n",
    "from src.compressors.compressor import Compressor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from load_dataset import Dataset\n",
    "import os\n",
    "\n",
    "import time\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up Julia.\n",
      "Finished starting up Julia.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting up Julia.\")\n",
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "from julia import Main\n",
    "Main.eval(\"using Random; Random.seed!(0)\")\n",
    "Main.include(\"src/compressors/fp8.jl\")\n",
    "print(\"Finished starting up Julia.\")\n",
    "\n",
    "FP8_FORMAT = (1, 5, 2)\n",
    "FP32_FORMAT = (1, 8, 23)\n",
    "\n",
    "def get_emax(format):\n",
    "    return (2**(format[1]-1)) - 1\n",
    "\n",
    "def get_emin(format):\n",
    "    return 1 - get_emax(format)\n",
    "\n",
    "\n",
    "class FP8(Compressor):\n",
    "    def __init__(self):\n",
    "        self.fp8s_repr_in_fp32 = []\n",
    "        self.fp8s = []\n",
    "        self.s = -1\n",
    "        # negative values before positive values.\n",
    "        def insert(num):\n",
    "            byte = struct.pack('>B', num)\n",
    "            [num] = self.decode(byte)\n",
    "            if not np.isnan(num):\n",
    "                self.fp8s.append(byte)\n",
    "                self.fp8s_repr_in_fp32.append(num)\n",
    "                bits = bitarray()\n",
    "                bits.frombytes(byte)\n",
    "        for i in list(reversed(range(128, 253))) + list(range(0, 128)):\n",
    "            insert(i)\n",
    "        self.fp8s_repr_in_fp32 = np.array(self.fp8s_repr_in_fp32).astype(np.float32)\n",
    "\n",
    "    def get_fp8_neighbors(self, f: np.float32) -> Tuple[bytes, bytes]:\n",
    "        idx_high = np.searchsorted(self.fp8s_repr_in_fp32, f, side='right')\n",
    "        idx_low = idx_high - 1\n",
    "        if idx_high == len(self.fp8s_repr_in_fp32):\n",
    "            idx_high -= 1\n",
    "        return self.fp8s[idx_low], self.fp8s[idx_high], self.fp8s_repr_in_fp32[idx_low], self.fp8s_repr_in_fp32[idx_high]\n",
    "\n",
    "    def encode(self, array: np.ndarray, seed=None, cid=\":-)\", client_name=\":-))\") -> bytes:\n",
    "        assert len(array.shape) == 1\n",
    "        assert array.dtype == np.float32\n",
    "        result = Main.encode_fp8(array, self.fp8s_repr_in_fp32, self.fp8s, seed)\n",
    "        return bytes(result)\n",
    "    \n",
    "    def decode(self, array: bytes, use_lo_quant=False) -> np.ndarray:\n",
    "        result = Main.decode_fp8(array)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1647267 , 7.782693  , 1.0144198 , 8.797519  , 6.6364665 ,\n",
       "       7.9669414 , 6.905339  , 3.1107771 , 7.9802046 , 3.836358  ,\n",
       "       8.260233  , 4.9297214 , 9.329671  , 1.4838758 , 0.05261961,\n",
       "       9.474543  ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list(np.random.rand(1,16).flatten()*10)\n",
    "arr = np.array(arr, dtype = np.float32)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'52.88461538461539% smaller '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp8 = FP8()\n",
    "enc = fp8.encode(arr)\n",
    "dec = fp8.decode(enc)\n",
    "import sys\n",
    "f\"{100 * (sys.getsizeof(dec)-sys.getsizeof(enc))/sys.getsizeof(dec)}% smaller \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MNIST_PAQ:\n",
    "\tdef __init__(self, filename=\"saved_models\", number_of_clients=1, aggregate_epochs=10, local_epochs=5, precision=7, r=1.0):\n",
    "\t\tself.model = None\n",
    "\t\tself.criterion = torch.nn.CrossEntropyLoss()\n",
    "\t\tself.optimizer = None\n",
    "\t\tself.number_of_clients = number_of_clients\n",
    "\t\tself.aggregate_epochs = aggregate_epochs\n",
    "\t\tself.local_epochs = local_epochs\n",
    "\t\tself.precision = precision\n",
    "\t\tself.r = r\n",
    "\t\tself.filename = filename\n",
    "\n",
    "\tdef define_model(self):\n",
    "\t\tself.model = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv2d(1, 2, kernel_size=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Conv2d(2, 4, kernel_size=7),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Flatten(),\n",
    "\t\t\ttorch.nn.Linear(1296, 512),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(512, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 32),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(32, 10),\n",
    "\t\t\ttorch.nn.Softmax(dim=1),\n",
    "\t\t)\t\t\n",
    "\n",
    "\tdef get_weights(self, dtype=np.float32):\n",
    "\t\tprecision = self.precision \n",
    "\t\tweights = []\n",
    "\t\tfor layer in self.model:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tweights.append([np.around(layer.weight.detach().numpy().astype(dtype), decimals=precision), np.around(layer.bias.detach().numpy().astype(dtype), decimals=precision)])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\treturn np.array(weights)\n",
    "\n",
    "\tdef set_weights(self, weights):\n",
    "\t\tindex = 0\n",
    "\t\tfor layer_no, layer in enumerate(self.model):\n",
    "\t\t\ttry:\n",
    "\t\t\t\t_ = self.model[layer_no].weight\n",
    "\t\t\t\tself.model[layer_no].weight = torch.nn.Parameter(weights[index][0])\n",
    "\t\t\t\tself.model[layer_no].bias = torch.nn.Parameter(weights[index][1])\n",
    "\t\t\t\tindex += 1\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\tdef average_weights(self, all_weights):\n",
    "\t\tall_weights = np.array(all_weights)\n",
    "\t\tall_weights = np.mean(all_weights, axis=0)\n",
    "\t\tall_weights = [[torch.from_numpy(i[0].astype(np.float32)), torch.from_numpy(i[1].astype(np.float32))] for i in all_weights]\n",
    "\t\treturn all_weights\n",
    "\n",
    "\tdef client_generator(self, train_x, train_y):\n",
    "\t\tnumber_of_clients = self.number_of_clients\n",
    "\t\tsize = train_y.shape[0]//number_of_clients\n",
    "\t\ttrain_x, train_y = train_x.numpy(), train_y.numpy()\n",
    "\t\ttrain_x = np.array([train_x[i:i+size] for i in range(0, len(train_x)-len(train_x)%size, size)])\n",
    "\t\ttrain_y = np.array([train_y[i:i+size] for i in range(0, len(train_y)-len(train_y)%size, size)])\n",
    "\t\ttrain_x = torch.from_numpy(train_x)\n",
    "\t\ttrain_y = torch.from_numpy(train_y)\n",
    "\t\treturn train_x, train_y\n",
    "\n",
    "\tdef single_client(self, dataset, weights, E):\n",
    "\t\tself.define_model()\n",
    "\t\tif weights is not None:\n",
    "\t\t\tself.set_weights(weights)\n",
    "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\t\tfor epoch in range(E):\n",
    "\t\t\trunning_loss = 0\n",
    "\t\t\tfor batch_x, target in zip(dataset['x'], dataset['y']):\n",
    "\t\t\t\toutput = self.model(batch_x)\n",
    "\t\t\t\tloss = self.criterion(output, target)\n",
    "\t\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tself.optimizer.step()\n",
    "\t\t\t\trunning_loss += loss.item()\n",
    "\t\t\trunning_loss /= len(dataset['y'])\n",
    "\t\tweights = self.get_weights()\n",
    "\t\t\n",
    "\t\treturn weights, running_loss\n",
    "\n",
    "\tdef test_aggregated_model(self, test_x, test_y, epoch):\n",
    "\t\tacc = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor batch_x, batch_y in zip(test_x, test_y):\n",
    "\t\t\t\ty_pred = self.model(batch_x)\n",
    "\t\t\t\ty_pred = torch.argmax(y_pred, dim=1)\n",
    "\t\t\t\tacc += torch.sum(y_pred == batch_y)/y_pred.shape[0]\n",
    "\t\ttorch.save(self.model, \"./\"+self.filename+\"/model_epoch_\"+str(epoch+1)+\".pt\")\n",
    "\t\treturn (acc/test_x.shape[0])\n",
    "\t\t\t\n",
    "\n",
    "\tdef train_aggregator(self, datasets, datasets_test):\n",
    "\t\tlocal_epochs = self.local_epochs\n",
    "\t\taggregate_epochs = self.aggregate_epochs\n",
    "\t\tos.system('mkdir '+self.filename)\n",
    "\t\tE = local_epochs\n",
    "\t\taggregate_weights = None\n",
    "\t\tfor epoch in range(aggregate_epochs):\n",
    "\t\t\tall_weights = []\n",
    "\t\t\tclient = 0\n",
    "\t\t\trunning_loss = 0\n",
    "\t\t\tselections = np.arange(datasets['x'].shape[0])\n",
    "\t\t\tnp.random.shuffle(selections)\n",
    "\t\t\tselections = selections[:int(self.r*datasets['x'].shape[0])]\n",
    "\t\t\tclients = tqdm(zip(datasets['x'][selections], datasets['y'][selections]), total=selections.shape[0])\n",
    "\t\t\tfor dataset_x, dataset_y in clients:\n",
    "\t\t\t\tdataset = {'x':dataset_x, 'y':dataset_y}\n",
    "\t\t\t\tweights, loss = self.single_client(dataset, aggregate_weights, E)\n",
    "\t\t\t\trunning_loss += loss\n",
    "\t\t\t\tall_weights.append(weights)\n",
    "\t\t\t\tclient += 1\n",
    "\t\t\t\tclients.set_description(str({\"Epoch\":epoch+1,\"Loss\": round(running_loss/client, 5)}))\n",
    "\t\t\t\tclients.refresh()\n",
    "\t\t\taggregate_weights = self.average_weights(all_weights)\n",
    "\t\t\tself.set_weights(aggregate_weights)\n",
    "\t\t\ttest_acc = self.test_aggregated_model(datasets_test['x'], datasets_test['y'], epoch)\n",
    "\t\t\tprint(\"Test Accuracy:\", round(test_acc.item(), 5))\n",
    "\t\t\tclients.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_PAQ_FP8:\n",
    "\tdef __init__(self, filename=\"saved_models\", number_of_clients=1, aggregate_epochs=10, local_epochs=5, precision=7, r=1.0):\n",
    "\t\tself.model = None\n",
    "\t\tself.criterion = torch.nn.CrossEntropyLoss()\n",
    "\t\tself.optimizer = None\n",
    "\t\tself.number_of_clients = number_of_clients\n",
    "\t\tself.aggregate_epochs = aggregate_epochs\n",
    "\t\tself.local_epochs = local_epochs\n",
    "\t\tself.precision = precision\n",
    "\t\tself.r = r\n",
    "\t\tself.filename = filename\n",
    "\n",
    "\tdef define_model(self):\n",
    "\t\tself.model = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv2d(1, 2, kernel_size=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Conv2d(2, 4, kernel_size=7),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Flatten(),\n",
    "\t\t\ttorch.nn.Linear(1296, 512),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(512, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 32),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(32, 10),\n",
    "\t\t\ttorch.nn.Softmax(dim=1),\n",
    "\t\t)\t\t\n",
    "\n",
    "\tdef get_weights(self, dtype=np.float32):\n",
    "\t\tprecision = self.precision \n",
    "\t\tweights = []\n",
    "\t\tfor layer in self.model:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tweights.append([np.around(layer.weight.detach().numpy().astype(dtype), decimals=precision), np.around(layer.bias.detach().numpy().astype(dtype), decimals=precision)])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\treturn np.array(weights)\n",
    "\n",
    "\tdef set_weights(self, weights):\n",
    "\t\tindex = 0\n",
    "\t\tfor layer_no, layer in enumerate(self.model):\n",
    "\t\t\ttry:\n",
    "\t\t\t\t_ = self.model[layer_no].weight\n",
    "\t\t\t\tself.model[layer_no].weight = torch.nn.Parameter(weights[index][0])\n",
    "\t\t\t\tself.model[layer_no].bias = torch.nn.Parameter(weights[index][1])\n",
    "\t\t\t\tindex += 1\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\tdef average_weights(self, all_weights):\n",
    "\t\tall_weights = np.array(all_weights)\n",
    "\t\tall_weights = np.mean(all_weights, axis=0)\n",
    "\t\tall_weights = [[torch.from_numpy(i[0].astype(np.float32)), torch.from_numpy(i[1].astype(np.float32))] for i in all_weights]\n",
    "\t\treturn all_weights\n",
    "\n",
    "\tdef client_generator(self, train_x, train_y):\n",
    "\t\tnumber_of_clients = self.number_of_clients\n",
    "\t\tsize = train_y.shape[0]//number_of_clients\n",
    "\t\ttrain_x, train_y = train_x.numpy(), train_y.numpy()\n",
    "\t\ttrain_x = np.array([train_x[i:i+size] for i in range(0, len(train_x)-len(train_x)%size, size)])\n",
    "\t\ttrain_y = np.array([train_y[i:i+size] for i in range(0, len(train_y)-len(train_y)%size, size)])\n",
    "\t\ttrain_x = torch.from_numpy(train_x)\n",
    "\t\ttrain_y = torch.from_numpy(train_y)\n",
    "\t\treturn train_x, train_y\n",
    "\n",
    "\tdef single_client(self, dataset, weights, E):\n",
    "\t\tself.define_model()\n",
    "\t\tif weights is not None:\n",
    "\t\t\tself.set_weights(weights)\n",
    "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\t\tfor epoch in range(E):\n",
    "\t\t\trunning_loss = 0\n",
    "\t\t\tfor batch_x, target in zip(dataset['x'], dataset['y']):\n",
    "\t\t\t\toutput = self.model(batch_x)\n",
    "\t\t\t\tloss = self.criterion(output, target)\n",
    "\t\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tself.optimizer.step()\n",
    "\t\t\t\trunning_loss += loss.item()\n",
    "\t\t\trunning_loss /= len(dataset['y'])\n",
    "\t\tweights = self.get_weights()\n",
    "\t\tfp8_weights = fp8.encode(weights)\n",
    "        \n",
    "\t\treturn fp8_weights, running_loss\n",
    "\tdef test_aggregated_model(self, test_x, test_y, epoch):\n",
    "\t\tacc = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor batch_x, batch_y in zip(test_x, test_y):\n",
    "\t\t\t\ty_pred = self.model(batch_x)\n",
    "\t\t\t\ty_pred = torch.argmax(y_pred, dim=1)\n",
    "\t\t\t\tacc += torch.sum(y_pred == batch_y)/y_pred.shape[0]\n",
    "\t\ttorch.save(self.model, \"./\"+self.filename+\"/model_epoch_\"+str(epoch+1)+\".pt\")\n",
    "\t\treturn (acc/test_x.shape[0])\n",
    "\t\t\t\n",
    "\n",
    "\tdef train_aggregator(self, datasets, datasets_test):\n",
    "\t\tlocal_epochs = self.local_epochs\n",
    "\t\taggregate_epochs = self.aggregate_epochs\n",
    "\t\tos.system('mkdir '+self.filename)\n",
    "\t\tE = local_epochs\n",
    "\t\taggregate_weights = None\n",
    "\t\tfor epoch in range(aggregate_epochs):\n",
    "\t\t\tall_weights = []\n",
    "\t\t\tclient = 0\n",
    "\t\t\trunning_loss = 0\n",
    "\t\t\tselections = np.arange(datasets['x'].shape[0])\n",
    "\t\t\tnp.random.shuffle(selections)\n",
    "\t\t\tselections = selections[:int(self.r*datasets['x'].shape[0])]\n",
    "\t\t\tclients = tqdm(zip(datasets['x'][selections], datasets['y'][selections]), total=selections.shape[0])\n",
    "\t\t\tfor dataset_x, dataset_y in clients:\n",
    "\t\t\t\tdataset = {'x':dataset_x, 'y':dataset_y}\n",
    "\t\t\t\tenc_weights, loss = self.single_client(dataset, aggregate_weights, E)\n",
    "\t\t\t\trunning_loss += loss\n",
    "\t\t\t\tweights = fp8.decode(enc_weights)\n",
    "\t\t\t\tall_weights.append(weights)\n",
    "\t\t\t\tclient += 1\n",
    "\t\t\t\tclients.set_description(str({\"Epoch\":epoch+1,\"Loss\": round(running_loss/client, 5)}))\n",
    "\t\t\t\tclients.refresh()\n",
    "\t\t\taggregate_weights = self.average_weights(all_weights)\n",
    "\t\t\tself.set_weights(aggregate_weights)\n",
    "\t\t\ttest_acc = self.test_aggregated_model(datasets_test['x'], datasets_test['y'], epoch)\n",
    "\t\t\tprint(\"Test Accuracy:\", round(test_acc.item(), 5))\n",
    "\t\t\tclients.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:16:45.985079\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the current time without the date\n",
    "\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_input_dim1 = np.array([-0.12629233, -0.1362397, 0.08078203, 0.07553388, -0.19623], dtype=np.float32)\n",
    "encoded = fp8.encode(array_input_dim1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.125   , -0.125   ,  0.078125,  0.078125, -0.1875  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = fp8.decode(encoded)\n",
    "f\"{100 * (sys.getsizeof(decoded)-sys.getsizeof(encoded))/sys.getsizeof(dec)}% smaller \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_array = np.array(\n",
    "    [[[[ -0.12629233, -0.1362397 ,  0.08078203,  0.07553388, -0.19623   ],\n",
    "       [  0.02517655,  0.03846296,  0.01871455,  0.01617125,  0.1448636 ],\n",
    "       [ -0.07328834,  0.05776931, -0.1460402 ,  0.04494672,  0.05415818],\n",
    "       [ -0.07904101, -0.06904116,  0.04111809, -0.13898756,  0.0417274 ],\n",
    "       [ -0.1289949 ,  0.07018968, -0.10922919, -0.08923879, -0.06198747]]],\n",
    "\n",
    "      [[[-0.07116126, -0.09482241,  0.1228622 , -0.0914599 , -0.0037921 ],\n",
    "       [ 0.20101367, -0.15044504, -0.13406286,  0.09263736, -0.09471569],\n",
    "       [ -0.00387396, -0.13878612, -0.16274846,  0.1638582 ,  0.03179684],\n",
    "       [ -0.0862455 ,  0.12387744,  0.10004783,  0.06132166, -0.02224598],\n",
    "       [ -0.19546221,  0.17359096, -0.06908803, -0.1917584 , -0.1780581 ]]]],\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "encoded = fp8.encode(existing_array.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded\n",
    "decoded = fp8.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.125     , -0.15625   ,  0.078125  ,  0.078125  , -0.1875    ,\n",
       "        0.0234375 ,  0.0390625 ,  0.01953125,  0.01953125,  0.15625   ,\n",
       "       -0.0625    ,  0.0625    , -0.15625   ,  0.046875  ,  0.0546875 ,\n",
       "       -0.078125  , -0.0625    ,  0.0390625 , -0.15625   ,  0.0390625 ,\n",
       "       -0.125     ,  0.0625    , -0.109375  , -0.09375   , -0.0546875 ,\n",
       "       -0.078125  , -0.09375   ,  0.109375  , -0.09375   , -0.00390625,\n",
       "        0.21875   , -0.15625   , -0.125     ,  0.09375   , -0.09375   ,\n",
       "       -0.00390625, -0.15625   , -0.15625   ,  0.15625   ,  0.03125   ,\n",
       "       -0.078125  ,  0.125     ,  0.09375   ,  0.0546875 , -0.0234375 ,\n",
       "       -0.21875   ,  0.15625   , -0.0625    , -0.1875    , -0.15625   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
