{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schemes as sc\n",
    "from model import MNIST_PAQ_COMP,MNIST_PAQ_COMP_ADAPTIVE \n",
    "\n",
    "\n",
    "\n",
    "from load_dataset import Dataset\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27586206896551724"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.get_efficiency(sc.Custom_linear())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19047619047619047"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.get_efficiency(sc.customFreq_1_5())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [0.7566816  0.3074451  0.8939189  0.3866898  0.87385464 0.07623586\n",
      " 0.3765722  0.32655403 0.9408179  0.48312193 0.55546725 0.334706\n",
      " 0.28331634 0.5110989  0.5594255  0.6458654 ]\n",
      "Encoded [3822393318 1245889824 4294967295 2175506503 3614236915 1081460852\n",
      " 1084719233 1728903523 3366925843 1667425989  726524250  469755745\n",
      "          0 1282924090  676045071  397722513]\n",
      "After Quantization:  [0.75668158 0.30744515 0.89391888 0.38668986 0.87385463 0.07623591\n",
      " 0.37657221 0.32655406 0.94081779 0.48312199 0.55546728 0.33470603\n",
      " 0.28331629 0.51109892 0.55942545 0.64586541]\n",
      "<class 'numpy.uint16'> 27.586206896551722% smaller \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27586206896551724"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.get_efficiency(sc.customFreq_2(),debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code using Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/164 [00:00<?, ?it/s]e:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\model.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(weights),start_size,end_size\n",
      "{'Epoch': 1, 'Loss': 2.30101}: 100%|██████████| 164/164 [00:26<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.08766\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 2, 'Loss': 2.13684}: 100%|██████████| 164/164 [00:23<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.32669\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 3, 'Loss': 1.98386}: 100%|██████████| 164/164 [00:24<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.46929\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 4, 'Loss': 1.81527}: 100%|██████████| 164/164 [00:23<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.56042\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 5, 'Loss': 1.61457}: 100%|██████████| 164/164 [00:24<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.80788\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 6, 'Loss': 1.53362}: 100%|██████████| 164/164 [00:25<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.92829\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 7, 'Loss': 1.51868}:  74%|███████▍  | 122/164 [00:19<00:06,  6.53it/s]"
     ]
    }
   ],
   "source": [
    "number_of_clients = 328\n",
    "aggregate_epochs = 10\n",
    "local_epochs = 3\n",
    "r = 0.5\n",
    "\n",
    "current_time = datetime.now().time()\n",
    "epoch_time = time.time()\n",
    "tic = time.time()\n",
    "filename = f\"saved_models_{epoch_time}\"\n",
    "\n",
    "train_x, train_y, test_x, test_y = Dataset().load_csv()\n",
    "cmp = sc.FP8()\n",
    "\n",
    "m_8 = MNIST_PAQ_COMP(cmp = cmp, filename=filename, r=r, number_of_clients=number_of_clients, aggregate_epochs=aggregate_epochs, local_epochs=local_epochs)\n",
    "train_x, train_y = m_8.client_generator(train_x, train_y)\n",
    "result = m_8.train_aggregator({'x':train_x, 'y':train_y}, {'x':test_x, 'y':test_y})\n",
    "print(\"Time Taken: \", time.time()-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '█' (U+2588) (3801055838.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    {'Epoch': 1, 'Loss': 2.30103}: 100%|██████████| 164/164 [00:25<00:00,  6.32it/s]\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '█' (U+2588)\n"
     ]
    }
   ],
   "source": [
    "{'Epoch': 1, 'Loss': 2.30103}: 100%|██████████| 164/164 [00:25<00:00,  6.32it/s]\n",
    "Test Accuracy: 0.10314\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 2, 'Loss': 2.06086}: 100%|██████████| 164/164 [00:25<00:00,  6.46it/s]\n",
    "Test Accuracy: 0.44571\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 3, 'Loss': 1.87102}: 100%|██████████| 164/164 [00:26<00:00,  6.26it/s]\n",
    "Test Accuracy: 0.61583\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 4, 'Loss': 1.82189}: 100%|██████████| 164/164 [00:26<00:00,  6.17it/s]\n",
    "Test Accuracy: 0.64951\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 5, 'Loss': 1.77266}: 100%|██████████| 164/164 [00:26<00:00,  6.11it/s]\n",
    "Test Accuracy: 0.65991\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 6, 'Loss': 1.71054}: 100%|██████████| 164/164 [00:26<00:00,  6.15it/s]\n",
    "Test Accuracy: 0.75634\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 7, 'Loss': 1.69883}: 100%|██████████| 164/164 [00:28<00:00,  5.80it/s]\n",
    "Test Accuracy: 0.76032\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 8, 'Loss': 1.64535}: 100%|██████████| 164/164 [00:27<00:00,  6.00it/s]\n",
    "Test Accuracy: 0.80494\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 9, 'Loss': 1.61052}: 100%|██████████| 164/164 [00:26<00:00,  6.08it/s]\n",
    "Test Accuracy: 0.84934\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "{'Epoch': 10, 'Loss': 1.60017}: 100%|██████████| 164/164 [00:27<00:00,  6.03it/s]\n",
    "Test Accuracy: 0.85504\n",
    "Compression Ratio  99.97330216770052\n",
    "start_size: 2867.7421875,end_size: 784\n",
    "Time Taken:  280.32285833358765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_1 = r'E:\\MS_Thesis\\Pre-defense-june\\Results_for_update\\proposed_variations.csv'\n",
    "\n",
    "\n",
    "result =  pd.DataFrame(result, columns=m_8.cell_column_names)\n",
    "display(result)\n",
    "if os.path.exists(file_path_1):\n",
    "    # Read the existing CSV file\n",
    "    existing_data = pd.read_csv(file_path_1)\n",
    "    \n",
    "    # Identify the last epoch in the current run\n",
    "    last_epoch = result['Epoch'].max()\n",
    "    \n",
    "    # Iterate over the new results and update the existing ones if necessary\n",
    "    for index, row in result.iterrows():\n",
    "        scheme_name = row['scheme_name']\n",
    "        epoch = row['Epoch']\n",
    "        new_acc = row['Acc']\n",
    "        \n",
    "        # Check if the scheme_name and epoch already exist in the existing data\n",
    "        existing_entry = existing_data[(existing_data['scheme_name'] == scheme_name) & (existing_data['Epoch'] == epoch)]\n",
    "        \n",
    "        if not existing_entry.empty:\n",
    "            # Check if the new accuracy at the last epoch is greater than the existing one\n",
    "            if epoch == last_epoch:\n",
    "                existing_last_epoch_entry = existing_data[(existing_data['scheme_name'] == scheme_name) & (existing_data['Epoch'] == last_epoch)]\n",
    "                if new_acc > existing_last_epoch_entry['Acc'].values[0]:\n",
    "                    # Update the existing entry\n",
    "                    existing_data.loc[(existing_data['scheme_name'] == scheme_name) & (existing_data['Epoch'] == epoch), ['Loss', 'Acc']] = row[['Loss', 'Acc']]\n",
    "        else:\n",
    "            # Append the new row to the existing data\n",
    "            # existing_data = existing_data.append(row, ignore_index=True)\n",
    "            existing_data = pd.concat([existing_data, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    # Save the updated data back to the CSV file\n",
    "    existing_data.to_csv(file_path_1, index=False)\n",
    "else:\n",
    "    # If the file does not exist, save the new result as a new CSV file\n",
    "    result.to_csv(file_path_1, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<schemes.customFreq_2 object at 0x000002A4B1EDAEC0>: 0.275862069, <schemes.QSGD object at 0x000002A4B1F3B370>: 0.528846154, <schemes.Custom_linear_16 object at 0x000002A4B1EBF220>: 0.413793103}\n",
      "dict_keys([<schemes.QSGD object at 0x000002A4B1F3B370>, <schemes.Custom_linear_16 object at 0x000002A4B1EBF220>, <schemes.customFreq_2 object at 0x000002A4B1EDAEC0>])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/164 [00:00<?, ?it/s]e:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\model.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  weight_array = np.array(weights)\n",
      "e:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\model.py:254: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(weights),start_size,end_size\n",
      "{'Epoch': 1, 'Loss': 2.30105}: 100%|██████████| 164/164 [00:27<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.10106\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 2, 'Loss': 1.97014}: 100%|██████████| 164/164 [00:25<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.43947\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 3, 'Loss': 1.65861}: 100%|██████████| 164/164 [00:27<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.82852\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 4, 'Loss': 1.588}: 100%|██████████| 164/164 [00:27<00:00,  6.05it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87923\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 5, 'Loss': 1.557}: 100%|██████████| 164/164 [00:26<00:00,  6.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.90127\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 6, 'Loss': 1.54008}: 100%|██████████| 164/164 [00:26<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.91897\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 7, 'Loss': 1.53749}: 100%|██████████| 164/164 [00:26<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.92524\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 8, 'Loss': 1.52304}: 100%|██████████| 164/164 [00:26<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.93191\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 9, 'Loss': 1.51883}: 100%|██████████| 164/164 [00:26<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.94026\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 10, 'Loss': 1.51467}: 100%|██████████| 164/164 [00:27<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.93872\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n",
      "Time Taken:  0:04:42.358223\n"
     ]
    }
   ],
   "source": [
    "number_of_clients = 328\n",
    "aggregate_epochs = 10\n",
    "local_epochs = 3\n",
    "r = 0.5\n",
    "\n",
    "\n",
    "current_time = datetime.now().time()\n",
    "tic = datetime.now()\n",
    "filename = \"saved_models_x\"\n",
    "train_x, train_y, test_x, test_y = Dataset().load_csv()\n",
    "\n",
    "cmp_list = [sc.customFreq_2(),sc.QSGD(2,True),sc.Custom_linear_16()]\n",
    "d = {}\n",
    "\n",
    "for cmp in cmp_list:\n",
    "    name, acc, time, eff, combined = sc.get_time_efficiency_acc(cmp)\n",
    "    d[cmp] = eff\n",
    "    \n",
    "print(d)\n",
    "sorted_schemes = dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_schemes.keys())\n",
    "\n",
    "m_8 = MNIST_PAQ_COMP_ADAPTIVE(cmp_list=list(sorted_schemes.keys()), filename=filename, r=r, number_of_clients=number_of_clients, aggregate_epochs=aggregate_epochs, local_epochs=local_epochs)\n",
    "train_x, train_y = m_8.client_generator(train_x, train_y)\n",
    "agg_weights = m_8.train_aggregator({'x':train_x, 'y':train_y}, {'x':test_x, 'y':test_y})\n",
    "print(\"Time Taken: \", datetime.now()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<schemes.FP8 object at 0x0000012F068915A0>: 0.528846154, <schemes.FP8 object at 0x0000012F612C7EB0>: 0.528846154, <schemes.FP8 object at 0x0000012F612C7B80>: 0.528846154}\n",
      "dict_keys([<schemes.FP8 object at 0x0000012F068915A0>, <schemes.FP8 object at 0x0000012F612C7EB0>, <schemes.FP8 object at 0x0000012F612C7B80>])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/164 [00:00<?, ?it/s]d:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\model.py:249: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  weight_array = np.array(weights)\n",
      "d:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\model.py:256: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(weights),start_size,end_size\n",
      "{'Epoch': 1, 'Loss': 2.30105}: 100%|██████████| 164/164 [00:55<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.10314\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 2, 'Loss': 2.08109}: 100%|██████████| 164/164 [00:53<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2696\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 3, 'Loss': 1.78204}: 100%|██████████| 164/164 [00:55<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.64453\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 4, 'Loss': 1.6151}: 100%|██████████| 164/164 [00:57<00:00,  2.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84504\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 5, 'Loss': 1.57877}: 100%|██████████| 164/164 [00:58<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87962\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 6, 'Loss': 1.56042}: 100%|██████████| 164/164 [00:58<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.89482\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 7, 'Loss': 1.54859}: 100%|██████████| 164/164 [00:54<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.90507\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 8, 'Loss': 1.54977}: 100%|██████████| 164/164 [01:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.91202\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 9, 'Loss': 1.54071}: 100%|██████████| 164/164 [00:55<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.91886\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 10, 'Loss': 1.53121}: 100%|██████████| 164/164 [00:54<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.92291\n",
      "Compression Ratio  99.97330216770052\n",
      "start_size: 2867.7421875,end_size: 784\n",
      "Time Taken:  0:09:37.629378\n"
     ]
    }
   ],
   "source": [
    "number_of_clients = 328\n",
    "aggregate_epochs = 10\n",
    "local_epochs = 3\n",
    "r = 0.5\n",
    "\n",
    "\n",
    "current_time = datetime.now().time()\n",
    "tic = datetime.now()\n",
    "filename = \"saved_models_x\"\n",
    "train_x, train_y, test_x, test_y = Dataset().load_csv()\n",
    "\n",
    "# cmp_list = [sc.customFreq_2(),sc.QSGD(2,True),sc.Custom_linear_16()]\n",
    "# cmp_list = [sc.customFreq_2(),sc.customFreq_2(),sc.customFreq_2()]\n",
    "cmp_list = [sc.FP8(),sc.FP8(),sc.FP8()]\n",
    "\n",
    "d = {}\n",
    "\n",
    "for cmp in cmp_list:\n",
    "    name, acc, time, eff, combined = sc.get_time_efficiency_acc(cmp)\n",
    "    d[cmp] = eff\n",
    "    \n",
    "print(d)\n",
    "sorted_schemes = dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_schemes.keys())\n",
    "\n",
    "m_8 = MNIST_PAQ_COMP_ADAPTIVE(cmp_list=list(sorted_schemes.keys()), filename=filename, r=r, number_of_clients=number_of_clients, aggregate_epochs=aggregate_epochs, local_epochs=local_epochs)\n",
    "train_x, train_y = m_8.client_generator(train_x, train_y)\n",
    "agg_weights,client_details = m_8.train_aggregator({'x':train_x, 'y':train_y}, {'x':test_x, 'y':test_y},logging=True)\n",
    "print(\"Time Taken: \", datetime.now()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Latency Acc: 0.34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Convert dictionary to DataFrame\n",
    "df = pd.DataFrame.from_dict(client_details, orient='index')\n",
    "\n",
    "# Step 2: Rename the columns\n",
    "df.columns = ['Bandwidth', 'Traffic', 'Latency', 'Compression']\n",
    "\n",
    "# Step 3: Save to CSV file\n",
    "df.to_csv(r'D:\\MS_Thesis\\Pre-defense-june\\Results_for_update\\client_latency_data_FP8.csv', index=True)\n",
    "\n",
    "# Optional: Print the head of the DataFrame to verify\n",
    "average_latency = df['Latency'].mean()\n",
    "print(f'Average Latency Acc: {average_latency:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency\n",
    "customFreq_2 0.20\n",
    "Adaptive 0.13\n",
    "QSGD 0.12\n",
    "FP8 0.34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
