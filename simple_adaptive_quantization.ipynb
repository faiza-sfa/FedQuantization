{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# seeds \n",
        "seed_import = 265\n",
        "seed_QSGD = 155\n",
        "seed_customFreq_2_5 = 5454\n",
        "seed_Custom_linear_16 = 38763\n",
        "seed_Custom_linear = 5425\n",
        "seed_FP8 = 29855\n",
        "seed_FL_implementation = 546984"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Apr 28 07:08:16 2024\n",
        "\n",
        "\n",
        "@author: Faiza\n",
        "\"\"\"\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "import numpy as np\n",
        "import struct\n",
        "from typing import Tuple\n",
        "from bitarray import bitarray\n",
        "# from src.compressors.compressor import Compressor\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from load_dataset import Dataset\n",
        "import os\n",
        "\n",
        "import time\n",
        "# import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "import cv2\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "\n",
        "import math\n",
        "# from src.compressors.compressor import Compressor\n",
        "import struct\n",
        "\n",
        "\n",
        "from bitarray import bitarray\n",
        "from bitarray.util import int2ba, ba2int\n",
        "np.random.seed(seed_import)\n",
        "from scipy.fftpack import dct, idct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Compressor(ABC):\n",
        "    @abstractmethod\n",
        "    def encode(self, array: np.ndarray) -> bytes:\n",
        "        pass\n",
        "    @abstractmethod\n",
        "    def decode(self, array: bytes) -> np.ndarray:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Selected Schemes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\FedPAQ_env\\lib\\site-packages\\julia\\juliainfo.py:93: UserWarning: julia warned:\n",
            "The latest version of Julia in the `release` channel is 1.10.4+0.x64.w64.mingw32. You currently have `1.10.2+0.x64.w64.mingw32` installed. Run:\n",
            "\n",
            "  juliaup update\n",
            "\n",
            "in your terminal shell to install Julia 1.10.4+0.x64.w64.mingw32 and update the `release` channel to that version.\n",
            "  warnings.warn(\"{} warned:\\n{}\".format(julia, stderr))\n"
          ]
        }
      ],
      "source": [
        "class Compressor(ABC):\n",
        "    @abstractmethod\n",
        "    def encode(self, array: np.ndarray) -> bytes:\n",
        "        pass\n",
        "    @abstractmethod\n",
        "    def decode(self, array: bytes) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "\n",
        "from julia.api import Julia\n",
        "jl = Julia(compiled_modules=False)\n",
        "from julia import Main\n",
        "Main.eval(\"using Random; Random.seed!(0)\")\n",
        "Main.include(\"src/compressors/qsgd.jl\")\n",
        "Main.include(\"src/compressors/fp8.jl\")\n",
        "\n",
        "number_of_selected_schemes = 4\n",
        "column_names = [\"accuracy\",\"time\",\"efficiency\"]\n",
        "metrics_cell = np.zeros((number_of_selected_schemes, len(column_names)), dtype=object)\n",
        "\n",
        "# list = []\n",
        "# list.append(dict)\n",
        "# dict[qs]={{a,t,e}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#______________QSGD________________\n",
        "class QSGD(Compressor):\n",
        "    def __init__(self, s: int, zero_rle: bool, type=None):\n",
        "        np.random.seed(seed_QSGD)\n",
        "        self.type = type\n",
        "        if self.type == \"LFL\":\n",
        "            self.s = 2\n",
        "        else:\n",
        "            self.s = s\n",
        "        self.zero_rle = zero_rle\n",
        "        \n",
        "\n",
        "    # format:    | length | norm | s(1) | sign(1) | s(2) | ... | sign(n) | \n",
        "    # (no 0-rle) | 32     | 32   | ?    | 1       | ?    | ... | 1       |\n",
        "    # format:    | length | norm | n_zeros | s(1) | sign(1) | n_zeros | s(2) | ... | sign(n) |\n",
        "    # (0-rle)    | 32     | 32   | ?       | ?    | 1       | ?       | ?    | ... | 1       |\n",
        "    def encode(self, array: np.ndarray, seed=seed_QSGD, cid=\":-)\", client_name=\":-))\") -> bytes:\n",
        "        assert len(array.shape) == 1\n",
        "        assert array.dtype == np.float32\n",
        "        result = Main.encode_qsgd(array, self.s, self.type, seed, cid, client_name)\n",
        "        return bytes(result)\n",
        "\n",
        "    def decode(self, array: bytes, use_lo_quant=False) -> np.ndarray:\n",
        "        result = Main.decode_qsgd(array, self.s, self.type, use_lo_quant)\n",
        "        return result\n",
        "    \n",
        "\n",
        "FP8_FORMAT = (1, 5, 2)\n",
        "FP32_FORMAT = (1, 8, 23)\n",
        "\n",
        "def get_emax(format):\n",
        "    return (2**(format[1]-1)) - 1\n",
        "\n",
        "def get_emin(format):\n",
        "    return 1 - get_emax(format)\n",
        "\n",
        "# cmp = GZip(1)\n",
        "\n",
        "#______________FP8________________\n",
        "class FP8(Compressor):\n",
        "    def __init__(self):\n",
        "        np.random.seed(seed_FP8)\n",
        "        self.fp8s_repr_in_fp32 = []\n",
        "        self.fp8s = []\n",
        "        self.s = -1\n",
        "        # negative values before positive values.\n",
        "        def insert(num):\n",
        "            byte = struct.pack('>B', num)\n",
        "            [num] = self.decode(byte)\n",
        "            if not np.isnan(num):\n",
        "                self.fp8s.append(byte)\n",
        "                self.fp8s_repr_in_fp32.append(num)\n",
        "                bits = bitarray()\n",
        "                bits.frombytes(byte)\n",
        "        for i in list(reversed(range(128, 253))) + list(range(0, 128)):\n",
        "            insert(i)\n",
        "        self.fp8s_repr_in_fp32 = np.array(self.fp8s_repr_in_fp32).astype(np.float32)\n",
        "\n",
        "    def get_fp8_neighbors(self, f: np.float32) -> Tuple[bytes, bytes]:\n",
        "        idx_high = np.searchsorted(self.fp8s_repr_in_fp32, f, side='right')\n",
        "        idx_low = idx_high - 1\n",
        "        if idx_high == len(self.fp8s_repr_in_fp32):\n",
        "            idx_high -= 1\n",
        "        return self.fp8s[idx_low], self.fp8s[idx_high], self.fp8s_repr_in_fp32[idx_low], self.fp8s_repr_in_fp32[idx_high]\n",
        "\n",
        "    def encode(self, array: np.ndarray, seed=seed_FP8, cid=\":-)\", client_name=\":-))\") -> bytes:\n",
        "        assert len(array.shape) == 1\n",
        "        assert array.dtype == np.float32\n",
        "        result = Main.encode_fp8(array, self.fp8s_repr_in_fp32, self.fp8s, seed)\n",
        "        return bytes(result)\n",
        "    \n",
        "    def decode(self, array: bytes, use_lo_quant=False) -> np.ndarray:\n",
        "        result = Main.decode_fp8(array)\n",
        "        return result\n",
        "# cmp = FP8()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#______________Custom Linear________________\n",
        "class Custom_linear():\n",
        "    def __init__(self, quantization_type = np.uint32):\n",
        "        np.random.seed(seed_Custom_linear)\n",
        "        self.quantization_type = quantization_type\n",
        "        #quantization_level from 0 to 100\n",
        "        \n",
        "    def encode(self,data):\n",
        "        # data = data.astype(int)\n",
        "        self.xp = [data.min(), data.max()]\n",
        "        min = np.iinfo(self.quantization_type).min\n",
        "        max = np.iinfo(self.quantization_type).max\n",
        "\n",
        "        self.fp = [min, max]\n",
        "        enc = np.interp(data, self.xp, self.fp)\n",
        "        enc = enc.astype(self.quantization_type)\n",
        "        # encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), self.quantization_level] \n",
        "        # result, encimg = cv2.imencode('.jpg', img, encode_param)\n",
        "\n",
        "        return enc\n",
        "\n",
        "    def decode(self, enc) :\n",
        "        dec = np.interp(enc, self.fp, self.xp)\n",
        "        return dec\n",
        "\n",
        "# data_type = np.uint8\n",
        "# cmp = Custom_linear(data_type)\n",
        "\n",
        "\n",
        "class Custom_linear_16():\n",
        "    def __init__(self, quantization_type = np.uint16):\n",
        "        np.random.seed(seed_Custom_linear_16)\n",
        "        self.quantization_type = quantization_type\n",
        "        #quantization_level from 0 to 100\n",
        "        \n",
        "\n",
        "\n",
        "    def encode(self,data):\n",
        "        # data = data.astype(int)\n",
        "        self.xp = [data.min(), data.max()]\n",
        "        min = np.iinfo(self.quantization_type).min\n",
        "        max = np.iinfo(self.quantization_type).max\n",
        "\n",
        "        self.fp = [min, max]\n",
        "        enc = np.interp(data, self.xp, self.fp)\n",
        "        enc = enc.astype(self.quantization_type)\n",
        "        # encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), self.quantization_level] \n",
        "        # result, encimg = cv2.imencode('.jpg', img, encode_param)\n",
        "\n",
        "        return enc\n",
        "\n",
        "    def decode(self, enc) :\n",
        "        dec = np.interp(enc, self.fp, self.xp)\n",
        "        return dec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#______________Frequency Domain Quantization________________\n",
        "\n",
        "\n",
        "\n",
        "class customFreq_2():\n",
        "    # def __init__(self, precision_levels = [8, 4, 2]):\n",
        "    def __init__(self, precision_levels = [32, 16, 8]):\n",
        "        np.random.seed(seed_customFreq_2_5)\n",
        "        self.precision_levels = precision_levels\n",
        "        self.linearQuant = Custom_linear()\n",
        "        #quantization_level from 0 to 100  \n",
        "              \n",
        "    def dct_transform(self, x):\n",
        "        return dct(dct(x, axis=-1, norm='ortho'), axis=-1, norm='ortho')\n",
        "\n",
        "    def inverse_dct_transform(self, x):\n",
        "        return idct(idct(x, axis=-1, norm='ortho'), axis=-1, norm='ortho')\n",
        "\n",
        "    def quantize(self, x, precision):\n",
        "        scale = 2 ** (precision - 1) - 1\n",
        "        return np.round(x * scale) / scale\n",
        "\n",
        "\n",
        "    def encode(self, weights):\n",
        "        # Apply DCT to transform weights to the frequency domain\n",
        "        weights_f = self.dct_transform(weights)\n",
        "        # Quantize frequency components\n",
        "        enc = self.linearQuant.encode(weights_f)\n",
        "        # enc = enc.astype(np.float16)\n",
        "        return enc\n",
        "\n",
        "    def decode(self, enc) :\n",
        "        weights_quantized = self.linearQuant.decode(enc)\n",
        "        weights_quantized = self.inverse_dct_transform(weights_quantized)\n",
        "        return weights_quantized\n",
        "    \n",
        "# cmp = customFreq_2_5()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def get_time_efficiency_acc(cmp):\n",
        "\n",
        "    df_acc_loss = pd.read_csv(\"E:\\MS_Thesis\\Pre-defense-june\\Results_for_update\\scheme_ACC_LOSS_sheet.csv\")\n",
        "\n",
        "    acc_loss = df_acc_loss[df_acc_loss['Epoch']==9]\n",
        "    acc_loss = acc_loss.drop(['Epoch'], axis=1)\n",
        "    df_time_eff = pd.read_csv(\"E:\\MS_Thesis\\Pre-defense-june\\Results_for_update\\scheme_TIME_EFF_sheet.csv\")\n",
        "    df_properties = pd.merge(acc_loss, df_time_eff, on='scheme_name')\n",
        "    # print(df_properties)\n",
        "    scaler = MinMaxScaler()\n",
        "    df_properties_scaled = df_properties.copy()\n",
        "    df_properties_scaled[['Acc', 'Time', 'Efficiency']] = scaler.fit_transform(df_properties_scaled[['Acc', 'Time', 'Efficiency']])\n",
        "    weights = {\n",
        "        'Acc': 0.5,\n",
        "        'Time': 0.3,\n",
        "        'Efficiency': 0.2\n",
        "    }\n",
        "\n",
        "    # Compute the combined measure\n",
        "    df_properties_scaled['Combined_Score'] = (\n",
        "        weights['Acc'] * df_properties_scaled['Acc'] +\n",
        "        weights['Time'] * (1 - df_properties_scaled['Time']) +  \n",
        "        weights['Efficiency'] * df_properties_scaled['Efficiency']\n",
        "    )\n",
        "\n",
        "\n",
        "    name = cmp.__class__.__name__\n",
        "\n",
        "    time = df_properties[df_properties['scheme_name']==name]['Time'].values[0]\n",
        "    acc = df_properties[df_properties['scheme_name']==name]['Acc'].values[0]\n",
        "    eff = df_properties[df_properties['scheme_name']==name]['Efficiency'].values[0]\n",
        "\n",
        "    combined = df_properties_scaled[df_properties_scaled['scheme_name']==name]['Combined_Score'].values[0]\n",
        "\n",
        "\n",
        "    return name, acc, time, eff, combined\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Federated Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%% PAQ with Compression\n",
        "\n",
        "\n",
        "class MNIST_PAQ_COMP:\n",
        "\tdef __init__(self, cmp_list, filename=\"saved_models\", number_of_clients=1, aggregate_epochs=10, local_epochs=5, precision=7, r=1.0):\n",
        "\t\t\n",
        "\t\tnp.random.seed(seed_FL_implementation)\n",
        "\t\tself.model = None\n",
        "\t\tself.criterion = torch.nn.CrossEntropyLoss()\n",
        "\t\tself.optimizer = None\n",
        "\t\tself.number_of_clients = number_of_clients\n",
        "\t\tself.aggregate_epochs = aggregate_epochs\n",
        "\t\tself.local_epochs = local_epochs\n",
        "\t\tself.precision = precision\n",
        "\t\tself.r = r\n",
        "\t\tself.filename = filename\n",
        "\t\tself.compression_ratio = 0\n",
        "\t\tself.cmp = None\n",
        "\t\tself.cmp_list = cmp_list\n",
        "\t\tself.client_ids = list(range(0,number_of_clients))\n",
        "\n",
        "\t\tself.bw_low = 20\t\t\n",
        "\t\tself.bw_high = 2500\n",
        "\n",
        "\t\tself.traffic_low = 1\n",
        "\t\tself.traffic_high = 51\n",
        "\t\t# self.bw_traffic = [[random.randint(self.bw_low, self.bw_high), random.randint(1,50)] for _ in range(number_of_clients)]\n",
        "\t\n",
        "\t\tbandwidths = np.random.randint(self.bw_low, self.bw_high + 1, size=self.number_of_clients)\n",
        "\t\ttraffic = np.random.randint(self.traffic_low, self.traffic_high, size=self.number_of_clients)\n",
        "\t\tself.bw_traffic = list(zip(bandwidths, traffic))\n",
        "\n",
        "\n",
        "#a list of tuple of shape(list) number_of_clients\n",
        "\n",
        "\tdef define_model(self):\n",
        "\t\tself.model = torch.nn.Sequential(\n",
        "\t\t\ttorch.nn.Conv2d(1, 2, kernel_size=5),\n",
        "\t\t\ttorch.nn.ReLU(),\n",
        "\t\t\ttorch.nn.Conv2d(2, 4, kernel_size=7),\n",
        "\t\t\ttorch.nn.ReLU(),\n",
        "\t\t\ttorch.nn.Flatten(),\n",
        "\t\t\ttorch.nn.Linear(1296, 512),\n",
        "\t\t\ttorch.nn.ReLU(),\n",
        "\t\t\ttorch.nn.Linear(512, 128),\n",
        "\t\t\ttorch.nn.ReLU(),\n",
        "\t\t\ttorch.nn.Linear(128, 32),\n",
        "\t\t\ttorch.nn.ReLU(),\n",
        "\t\t\ttorch.nn.Linear(32, 10),\n",
        "\t\t\ttorch.nn.Softmax(dim=1),\n",
        "\t\t)\t\t\n",
        "\n",
        "\tdef get_weights_custom(self, dtype=np.float32):\n",
        "        \n",
        "\t\tprecision = self.precision \n",
        "\t\tweights = []\n",
        "\t\tstart_size = 0\n",
        "\t\tend_size = 0\n",
        "        \n",
        "\n",
        "        \n",
        "\t\tfor layer in self.model:\t\t\t\n",
        "\t\t\ttry:\n",
        "\t\t\t\tlayer_weights = layer.weight.detach().numpy().astype(dtype)\n",
        "\t\t\t\tstart_size = start_size + sys.getsizeof(layer_weights)\n",
        "\t\t\t\t# layer_weights_enc = self.cmp.encode(layer_weights)\n",
        "\t\t\t\tlayer_weights_enc = self.cmp.encode(layer_weights.flatten())\n",
        "\t\t\t\tdecoded_weights = self.cmp.decode(layer_weights_enc)\n",
        "\t\t\t\tdecoded_weights = decoded_weights.astype(dtype)\n",
        "\t\t\t\tdecoded_weights = decoded_weights.reshape(layer_weights.shape)\n",
        "\t\t\t\tend_size = end_size + sys.getsizeof(decoded_weights)\n",
        "\t\t\n",
        "\t\t\t\tlayer_bias = layer.bias.detach().numpy().astype(dtype)\n",
        "\t\t\t\t# layer_bias_enc = self.cmp.encode(layer_bias)\t\n",
        "\t\t\t\tlayer_bias_enc = self.cmp.encode(layer_bias.flatten())\t\t\t\n",
        "\t\t\t\tdecoded_bias = self.cmp.decode(layer_bias_enc)\n",
        "\t\t\t\tdecoded_bias = decoded_bias.astype(dtype)\n",
        "\t\t\t\tdecoded_bias = decoded_bias.reshape(layer_bias.shape)\n",
        "\t\t\t\tweights.append([decoded_weights,decoded_bias])\n",
        "\t\t\t\t\n",
        "\t\t\texcept:\n",
        "\t\t\t\tcontinue\n",
        "\t\tself.compression_ratio = ((start_size-end_size)/start_size)*100\n",
        "\n",
        "\t\tweight_array = np.array(weights)\n",
        "\t\ttry:\n",
        "\t\t\tassert(weight_array.shape == (6,2))\n",
        "\t\texcept:\n",
        "\t\t\tprint('Scheme',self.cmp)\n",
        "\t\t\tprint('weight_array.shape',weight_array.shape)\n",
        "\n",
        "\t\treturn np.array(weights),start_size,end_size\n",
        "\n",
        "\n",
        "\n",
        "\tdef set_weights(self, weights):\n",
        "\t\tindex = 0\n",
        "\t\tfor layer_no, layer in enumerate(self.model):\n",
        "\t\t\ttry:\n",
        "\t\t\t\t_ = self.model[layer_no].weight\n",
        "\t\t\t\tself.model[layer_no].weight = torch.nn.Parameter(weights[index][0])\n",
        "\t\t\t\tself.model[layer_no].bias = torch.nn.Parameter(weights[index][1])\n",
        "\t\t\t\tindex += 1\n",
        "\t\t\texcept:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\tdef average_weights(self, all_weights):\n",
        "        \n",
        "\t\tall_weights = np.array(all_weights)\n",
        "\t\tall_weights = np.mean(all_weights, axis=0)\n",
        "\t\tall_weights = [[torch.from_numpy(i[0].astype(np.float32)), torch.from_numpy(i[1].astype(np.float32))] for i in all_weights]\n",
        "\t\treturn all_weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tdef get_client_bw_and_traffic(self,client_id):\n",
        "\t\tbw,traffic = self.bw_traffic[client_id]\n",
        "\t\treturn bw,traffic\n",
        "\t\n",
        "\n",
        "\n",
        "\tdef quanization_scheme(self,bw,traffic):\n",
        "\t\tnormalized_bw = bw/(self.bw_high-self.bw_low)\n",
        "\t\tnormalized_traffic = traffic/(self.traffic_high-self.traffic_low) \n",
        "\n",
        "\t\tclient_condition = normalized_bw * 50 + normalized_traffic * 50\n",
        "\n",
        "\t\tdata = np.arange(0,100)\n",
        "\t\tpercentile_33 = np.percentile(data, 33)\n",
        "\t\tpercentile_66 = np.percentile(data, 66)\n",
        "\n",
        "\t\tif client_condition<=percentile_33:\n",
        "\t\t\tselected_cmp = self.cmp_list[0]\n",
        "\t\telif percentile_33 < client_condition <= percentile_66:\n",
        "\t\t\tselected_cmp = self.cmp_list[1]\n",
        "\t\telse:\n",
        "\t\t\tselected_cmp = self.cmp_list[2]\t\t\t\n",
        "\t\treturn selected_cmp\n",
        "\t\n",
        "\t\t\n",
        "\n",
        "\tdef client_generator(self, train_x, train_y):\n",
        "\t\t\n",
        "\t\tnumber_of_clients = self.number_of_clients\n",
        "\t\tsize = train_y.shape[0]//number_of_clients\n",
        "\t\ttrain_x, train_y = train_x.numpy(), train_y.numpy()\n",
        "\t\ttrain_x = np.array([train_x[i:i+size] for i in range(0, len(train_x)-len(train_x)%size, size)])\n",
        "\t\ttrain_y = np.array([train_y[i:i+size] for i in range(0, len(train_y)-len(train_y)%size, size)])\n",
        "\t\ttrain_x = torch.from_numpy(train_x)\n",
        "\t\ttrain_y = torch.from_numpy(train_y)\n",
        "\t\t\n",
        "\t\treturn train_x, train_y\n",
        "\n",
        "\tdef single_client(self, dataset, weights, E):\n",
        "\t\tself.define_model()\n",
        "\t\tif weights is not None:\n",
        "\t\t\tself.set_weights(weights)\n",
        "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\t\tfor epoch in range(E):\n",
        "\t\t\trunning_loss = 0\n",
        "\t\t\tfor batch_x, target in zip(dataset['x'], dataset['y']):\n",
        "\t\t\t\toutput = self.model(batch_x)\n",
        "\t\t\t\tloss = self.criterion(output, target)\n",
        "\t\t\t\tself.optimizer.zero_grad()\n",
        "\t\t\t\tloss.backward()\n",
        "\t\t\t\tself.optimizer.step()\n",
        "\t\t\t\trunning_loss += loss.item()\n",
        "\t\t\trunning_loss /= len(dataset['y'])\n",
        "\t\t# weights,start_size,end_size = self.get_weights()\n",
        "\t\tweights,start_size,end_size = self.get_weights_custom()\t\t\n",
        "\t\treturn weights, running_loss, start_size,end_size\n",
        "\t\n",
        "\t\n",
        "\tdef test_aggregated_model(self, test_x, test_y, epoch):\n",
        "\t\tacc = 0\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tfor batch_x, batch_y in zip(test_x, test_y):\n",
        "\t\t\t\ty_pred = self.model(batch_x)\n",
        "\t\t\t\ty_pred = torch.argmax(y_pred, dim=1)\n",
        "\t\t\t\tacc += torch.sum(y_pred == batch_y)/y_pred.shape[0]\n",
        "\t\ttorch.save(self.model, \"./\"+self.filename+\"/model_epoch_\"+str(epoch+1)+\".pt\")\n",
        "\t\treturn (acc/test_x.shape[0])\n",
        "\t\t\t\n",
        "\n",
        "\tdef train_aggregator(self, datasets, datasets_test):\n",
        "\t\tlocal_epochs = self.local_epochs\n",
        "\t\taggregate_epochs = self.aggregate_epochs\n",
        "\t\tos.system('mkdir '+self.filename)\n",
        "\t\tE = local_epochs\n",
        "\t\taggregate_weights = None\n",
        "\t\tfor epoch in range(aggregate_epochs):\n",
        "\t\t\tall_weights = []\n",
        "\t\t\tclient = 0\n",
        "\t\t\trunning_loss = 0\n",
        "\t\t\tselections = np.arange(datasets['x'].shape[0])\n",
        "\t\t\tnp.random.shuffle(selections)\n",
        "\t\t\tselections = selections[:int(self.r*datasets['x'].shape[0])]\n",
        "\t\t\tclients = tqdm(zip(datasets['x'][selections], datasets['y'][selections]), total=selections.shape[0])\n",
        "\t\t\tfor selection_index,(dataset_x, dataset_y )in enumerate(clients):\n",
        "\t\t\t\tclient_id = selections[selection_index]\n",
        "\t\t\t\tbw,traffic = self.get_client_bw_and_traffic(client_id)\n",
        "\t\t\t\tself.cmp = self.quanization_scheme(bw,traffic)\n",
        "\t\t\t\t# print(self.cmp)\n",
        "\t\t\t\tdataset = {'x':dataset_x, 'y':dataset_y}\n",
        "\t\t\t\tweights, loss, start_size,end_size = self.single_client(dataset, aggregate_weights, E)\n",
        "\t\t\t\trunning_loss += loss\n",
        "\t\t\t\tall_weights.append(weights)\n",
        "\t\t\t\tclient += 1\n",
        "\t\t\t\tclients.set_description(str({\"Epoch\":epoch+1,\"Loss\": round(running_loss/client, 5)}))\n",
        "\t\t\t\t\n",
        "\t\t\t\tclients.refresh()\n",
        "\t\t\taggregate_weights = self.average_weights(all_weights)\n",
        "\t\t\tagg_weight = self.set_weights(aggregate_weights)\n",
        "\t\t\tself.test_acc = self.test_aggregated_model(datasets_test['x'], datasets_test['y'], epoch)\n",
        "\t\t\tprint(\"Test Accuracy:\", round(self.test_acc.item(), 5))\n",
        "\t\t\tprint(\"Compression Ratio \", self.compression_ratio)\n",
        "\t\t\t# print()\n",
        "\t\t\tprint(f'start_size: {start_size/1024},end_size: {end_size}')\n",
        "\t\t\tclients.close()\n",
        "\t\treturn agg_weight\n",
        "\t\n",
        "\tdef get_acc(self):\n",
        "\t\treturn self.test_acc\n",
        "\n",
        "\t\n",
        "\n",
        "\n",
        "#%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{<__main__.customFreq_2 object at 0x000002A89469A2C0>: 0.2758620689655172, <__main__.QSGD object at 0x000002A89469BCA0>: 0.5288461538461539, <__main__.Custom_linear_16 object at 0x000002A894698B50>: 0.4137931034482758}\n",
            "dict_keys([<__main__.QSGD object at 0x000002A89469BCA0>, <__main__.Custom_linear_16 object at 0x000002A894698B50>, <__main__.customFreq_2 object at 0x000002A89469A2C0>])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/164 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_6184\\577508066.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  weight_array = np.array(weights)\n",
            "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_6184\\577508066.py:92: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(weights),start_size,end_size\n",
            "{'Epoch': 1, 'Loss': 2.30154}:   2%|▏         | 4/164 [00:05<02:28,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30149}:   7%|▋         | 11/164 [00:05<00:29,  5.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30107}:  11%|█         | 18/164 [00:06<00:16,  8.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30103}:  18%|█▊        | 29/164 [00:07<00:15,  8.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30095}:  21%|██        | 34/164 [00:08<00:12, 10.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30088}:  25%|██▌       | 41/164 [00:09<00:12,  9.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30091}:  25%|██▌       | 41/164 [00:09<00:12,  9.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30081}:  28%|██▊       | 46/164 [00:09<00:13,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30078}:  33%|███▎      | 54/164 [00:10<00:10, 10.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30069}:  37%|███▋      | 60/164 [00:11<00:09, 10.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30067}:  38%|███▊      | 62/164 [00:11<00:09, 10.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.3007}:  39%|███▉      | 64/164 [00:11<00:09, 10.32it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30074}:  43%|████▎     | 71/164 [00:12<00:09,  9.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30077}:  46%|████▋     | 76/164 [00:12<00:08, 10.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30088}:  49%|████▉     | 81/164 [00:13<00:08, 10.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30088}:  52%|█████▏    | 85/164 [00:13<00:06, 11.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30093}:  55%|█████▌    | 91/164 [00:14<00:06, 10.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30094}:  60%|█████▉    | 98/164 [00:14<00:06, 10.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30094}:  63%|██████▎   | 103/164 [00:15<00:06,  9.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30096}:  65%|██████▍   | 106/164 [00:15<00:05,  9.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.301}:  67%|██████▋   | 110/164 [00:16<00:05, 10.57it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30098}:  70%|██████▉   | 114/164 [00:16<00:04, 10.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30099}:  72%|███████▏  | 118/164 [00:17<00:04, 11.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30098}:  77%|███████▋  | 126/164 [00:17<00:03, 10.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n",
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30098}:  79%|███████▉  | 130/164 [00:18<00:03,  9.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30101}:  96%|█████████▌| 157/164 [00:21<00:00,  8.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme <__main__.customFreq_2 object at 0x000002A89469A2C0>\n",
            "weight_array.shape (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 2.30101}: 100%|██████████| 164/164 [00:22<00:00,  7.39it/s]\n",
            "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_6184\\577508066.py:109: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  all_weights = np.array(all_weights)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (6,2) (0,) ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m m_8 \u001b[38;5;241m=\u001b[39m MNIST_PAQ_COMP(cmp_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(sorted_schemes\u001b[38;5;241m.\u001b[39mkeys()), filename\u001b[38;5;241m=\u001b[39mfilename, r\u001b[38;5;241m=\u001b[39mr, number_of_clients\u001b[38;5;241m=\u001b[39mnumber_of_clients, aggregate_epochs\u001b[38;5;241m=\u001b[39maggregate_epochs, local_epochs\u001b[38;5;241m=\u001b[39mlocal_epochs)\n\u001b[0;32m     26\u001b[0m train_x, train_y \u001b[38;5;241m=\u001b[39m m_8\u001b[38;5;241m.\u001b[39mclient_generator(train_x, train_y)\n\u001b[1;32m---> 27\u001b[0m agg_weights \u001b[38;5;241m=\u001b[39m \u001b[43mm_8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aggregator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime Taken: \u001b[39m\u001b[38;5;124m\"\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m-\u001b[39mtic)\n",
            "Cell \u001b[1;32mIn[6], line 213\u001b[0m, in \u001b[0;36mMNIST_PAQ_COMP.train_aggregator\u001b[1;34m(self, datasets, datasets_test)\u001b[0m\n\u001b[0;32m    210\u001b[0m \tclients\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;28mstr\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(running_loss\u001b[38;5;241m/\u001b[39mclient, \u001b[38;5;241m5\u001b[39m)}))\n\u001b[0;32m    212\u001b[0m \tclients\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m--> 213\u001b[0m aggregate_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m agg_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_weights(aggregate_weights)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_aggregated_model(datasets_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], datasets_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], epoch)\n",
            "Cell \u001b[1;32mIn[6], line 110\u001b[0m, in \u001b[0;36mMNIST_PAQ_COMP.average_weights\u001b[1;34m(self, all_weights)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maverage_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, all_weights):\n\u001b[0;32m    109\u001b[0m \tall_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_weights)\n\u001b[1;32m--> 110\u001b[0m \tall_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \tall_weights \u001b[38;5;241m=\u001b[39m [[torch\u001b[38;5;241m.\u001b[39mfrom_numpy(i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(i[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m all_weights]\n\u001b[0;32m    112\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m all_weights\n",
            "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32me:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\FedPAQ_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3438\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3441\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\FedPAQ_env\\lib\\site-packages\\numpy\\core\\_methods.py:179\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    176\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    177\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    181\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[0;32m    182\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,2) (0,) "
          ]
        }
      ],
      "source": [
        "number_of_clients = 328\n",
        "aggregate_epochs = 10\n",
        "local_epochs = 3\n",
        "r = 0.5\n",
        "current_time = datetime.now().time()\n",
        "# epoch_time = time.time()\n",
        "tic = datetime.now()\n",
        "filename = \"saved_models_x\"\n",
        "train_x, train_y, test_x, test_y = Dataset().load_csv()\n",
        "# cmp = customCompression(np.uint8)\n",
        "\n",
        "cmp_list = [customFreq_2(),QSGD(2,True),Custom_linear_16()]\n",
        "# cmp_list = [customFreq_2(),customFreq_2(),Custom_linear_16()]\n",
        "d = {}\n",
        "\n",
        "for cmp in cmp_list:\n",
        "    name, acc, time, eff, combined = get_time_efficiency_acc(cmp)\n",
        "    d[cmp] = eff\n",
        "    \n",
        "print(d)\n",
        "sorted_schemes = dict(sorted(d.items(), key=lambda item: item[1], reverse=True))\n",
        "print(sorted_schemes.keys())\n",
        "# cmp = FP8()\n",
        "# cmp = QSGD(2,True)\n",
        "m_8 = MNIST_PAQ_COMP(cmp_list=list(sorted_schemes.keys()), filename=filename, r=r, number_of_clients=number_of_clients, aggregate_epochs=aggregate_epochs, local_epochs=local_epochs)\n",
        "train_x, train_y = m_8.client_generator(train_x, train_y)\n",
        "agg_weights = m_8.train_aggregator({'x':train_x, 'y':train_y}, {'x':test_x, 'y':test_y})\n",
        "print(\"Time Taken: \", datetime.now()-tic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{<__main__.customFreq_2 object at 0x0000024FB139E800>: 0.2758620689655172, <__main__.QSGD object at 0x0000024FC38E37C0>: 0.5288461538461539, <__main__.Custom_linear_16 object at 0x0000024FC38E2E90>: 0.4137931034482758}\n",
        "dict_keys([<__main__.QSGD object at 0x0000024FC38E37C0>, <__main__.Custom_linear_16 object at 0x0000024FC38E2E90>, <__main__.customFreq_2 object at 0x0000024FB139E800>])\n",
        "  0%|          | 0/164 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7408\\3597313781.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
        "  weight_array = np.array(weights)\n",
        "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7408\\3597313781.py:92: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
        "  return np.array(weights),start_size,end_size\n",
        "{'Epoch': 1, 'Loss': 2.30106}: 100%|██████████| 164/164 [00:22<00:00,  7.26it/s]\n",
        "Test Accuracy: 0.10228\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 2, 'Loss': 1.95148}: 100%|██████████| 164/164 [00:24<00:00,  6.78it/s]\n",
        "Test Accuracy: 0.47029\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 3, 'Loss': 1.74089}: 100%|██████████| 164/164 [00:26<00:00,  6.19it/s]\n",
        "Test Accuracy: 0.73742\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 4, 'Loss': 1.68466}: 100%|██████████| 164/164 [00:24<00:00,  6.76it/s]\n",
        "Test Accuracy: 0.75613\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 5, 'Loss': 1.61751}: 100%|██████████| 164/164 [00:22<00:00,  7.16it/s]\n",
        "Test Accuracy: 0.83759\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 6, 'Loss': 1.60218}: 100%|██████████| 164/164 [00:24<00:00,  6.57it/s]\n",
        "Test Accuracy: 0.853\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 7, 'Loss': 1.59334}: 100%|██████████| 164/164 [00:24<00:00,  6.79it/s]\n",
        "Test Accuracy: 0.8574\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 8, 'Loss': 1.58873}: 100%|██████████| 164/164 [00:27<00:00,  6.05it/s]\n",
        "Test Accuracy: 0.86199\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 9, 'Loss': 1.53745}: 100%|██████████| 164/164 [00:23<00:00,  7.00it/s]\n",
        "Test Accuracy: 0.86518\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "{'Epoch': 10, 'Loss': 1.50526}: 100%|██████████| 164/164 [00:27<00:00,  5.86it/s]\n",
        "Test Accuracy: 0.94933\n",
        "Compression Ratio  99.97330216770052\n",
        "start_size: 2867.7421875,end_size: 784\n",
        "Time Taken:  0:04:27.716845"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor(0.9491)\n"
          ]
        }
      ],
      "source": [
        "print(agg_weights)\n",
        "\n",
        "print(m_8.get_acc())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # seeds \n",
        "# seed_import = 265\n",
        "# seed_QSGD = 155\n",
        "# seed_customFreq_2_5 = 5454\n",
        "# seed_Custom_linear_16 = 38763\n",
        "# seed_Custom_linear = 5425\n",
        "# seed_FP8 = 29855\n",
        "# seed_FL_implementation = 546984"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
