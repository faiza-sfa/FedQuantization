{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "numpy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[0;32m     51\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CIFARDataset(iid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m train_x, train_y, test_x, test_y \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_x\u001b[38;5;241m.\u001b[39mshape, train_y\u001b[38;5;241m.\u001b[39mshape, test_x\u001b[38;5;241m.\u001b[39mshape, test_y\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m, in \u001b[0;36mCIFARDataset.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39mcifar_location, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Extract data and labels from the dataset objects\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m train_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mtranspose(img\u001b[38;5;241m.\u001b[39mnumpy(), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m img, _ \u001b[38;5;129;01min\u001b[39;00m train_data])\n\u001b[0;32m     29\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m train_data])\n\u001b[0;32m     30\u001b[0m test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mtranspose(img\u001b[38;5;241m.\u001b[39mnumpy(), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m img, _ \u001b[38;5;129;01min\u001b[39;00m test_data])\n",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     25\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39mcifar_location, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Extract data and labels from the dataset objects\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m train_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m(), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m img, _ \u001b[38;5;129;01min\u001b[39;00m train_data])\n\u001b[0;32m     29\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m train_data])\n\u001b[0;32m     30\u001b[0m test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mtranspose(img\u001b[38;5;241m.\u001b[39mnumpy(), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m img, _ \u001b[38;5;129;01min\u001b[39;00m test_data])\n",
      "File \u001b[1;32md:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\FedPAQ_env\\lib\\site-packages\\PIL\\Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    512\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    516\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    517\u001b[0m     )\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: numpy"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "class CIFARDataset:\n",
    "    def __init__(self, iid=True, batch_size=128):\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.batch_size = batch_size\n",
    "        self.iid = iid\n",
    "\n",
    "    def load_data(self):\n",
    "        # Define the transformations\n",
    "        # transform = transforms.Compose([\n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        # ])\n",
    "\n",
    "        # Load the CIFAR-10 dataset\n",
    "        cifar_location = r'D:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\cifar-10\\cifar-10-python'\n",
    "        train_data = torchvision.datasets.CIFAR10(root=cifar_location, train=True, download=False)\n",
    "        test_data = torchvision.datasets.CIFAR10(root=cifar_location, train=False, download=False)\n",
    "\n",
    "        # Extract data and labels from the dataset objects\n",
    "        train_images = np.array([np.transpose(img.numpy(), (0, 1, 2)) for img, _ in train_data])\n",
    "        train_labels = np.array([label for _, label in train_data])\n",
    "        test_images = np.array([np.transpose(img.numpy(), (0, 1, 2)) for img, _ in test_data])\n",
    "        test_labels = np.array([label for _, label in test_data])\n",
    "\n",
    "        # If iid is False, sort data by label to simulate non-iid\n",
    "        if not self.iid:\n",
    "            sorted_indices = np.argsort(train_labels)\n",
    "            train_images, train_labels = train_images[sorted_indices], train_labels[sorted_indices]\n",
    "\n",
    "        # Normalize and reshape for PyTorch compatibility\n",
    "        self.train_x = np.array([train_images[n:n + self.batch_size] for n in range(0, len(train_images) - self.batch_size, self.batch_size)], dtype=np.float32)\n",
    "        self.train_y = np.array([train_labels[n:n + self.batch_size] for n in range(0, len(train_labels) - self.batch_size, self.batch_size)])\n",
    "        self.test_x = np.array([test_images[n:n + self.batch_size] for n in range(0, len(test_images) - self.batch_size, self.batch_size)], dtype=np.float32)\n",
    "        self.test_y = np.array([test_labels[n:n + self.batch_size] for n in range(0, len(test_labels) - self.batch_size, self.batch_size)])\n",
    "\n",
    "        # Convert numpy arrays to torch tensors\n",
    "        self.train_x, self.train_y = torch.tensor(self.train_x), torch.tensor(self.train_y)\n",
    "        self.test_x, self.test_y = torch.tensor(self.test_x), torch.tensor(self.test_y)\n",
    "\n",
    "        return self.train_x, self.train_y, self.test_x, self.test_y\n",
    "\n",
    "# Usage example\n",
    "dataset = CIFARDataset(iid=True, batch_size=128)\n",
    "train_x, train_y, test_x, test_y = dataset.load_data()\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "\n",
    "cifar_location = r'D:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\cifar-10\\cifar-10-python'\n",
    "\n",
    "class CIFAR10Dataset:\n",
    "    def __init__(self, iid=True, batch_size=128):\n",
    "        self.batch_size = batch_size\n",
    "        self.iid = iid\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "\n",
    "    def load_data(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        # Download and load the training data\n",
    "        trainset = torchvision.datasets.CIFAR10(root=cifar_location, train=True, download=False, transform=transform)\n",
    "        \n",
    "        # Download and load the test data\n",
    "        testset = torchvision.datasets.CIFAR10(root=cifar_location, train=False, download=False, transform=transform)\n",
    "\n",
    "        # Calculate number of batches\n",
    "        num_batches = len(trainset.data) // self.batch_size\n",
    "\n",
    "        # Truncate the dataset to a multiple of the batch size\n",
    "        train_x = trainset.data[:num_batches * self.batch_size]\n",
    "        train_y = np.array(trainset.targets[:num_batches * self.batch_size])\n",
    "\n",
    "        # Reshape into batches\n",
    "        train_x_batches = train_x.reshape(num_batches, self.batch_size, *train_x.shape[1:])\n",
    "        train_y_batches = train_y.reshape(num_batches, self.batch_size)\n",
    "        \n",
    "        return trainset.targets, trainset.data, testset.targets, testset.data\n",
    "\n",
    "    def load_data_2(self):\n",
    "        batch_size = self.batch_size\n",
    "        trainset = torchvision.datasets.CIFAR10(root=cifar_location, train=True, download=False)\n",
    "        testset = torchvision.datasets.CIFAR10(root=cifar_location, train=False, download=False)\n",
    "\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = trainset.data, testset.data, trainset.targets, testset.targets\n",
    "\n",
    "        self.train_x = np.array([self.train_x[n:n+batch_size] for n in range(0, len(self.train_x)-batch_size, batch_size)])/255.0\n",
    "        self.test_x = np.array([self.test_x[n:n+batch_size] for n in range(0, len(self.test_x)-batch_size, batch_size)])/255.0\n",
    "        self.train_y = np.array([self.train_y[n:n+batch_size] for n in range(0, len(self.train_y)-batch_size, batch_size)])\n",
    "        self.test_y = np.array([self.test_y[n:n+batch_size] for n in range(0, len(self.test_y)-batch_size, batch_size)])\n",
    "\n",
    "        self.train_x, self.train_y, self.test_x, self.test_y = torch.from_numpy(self.train_x), torch.from_numpy(self.train_y), torch.from_numpy(self.test_x), torch.from_numpy(self.test_y)\n",
    "\n",
    "        return self.train_x, self.train_y, self.test_x, self.test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10Dataset(iid=True, batch_size=128)\n",
    "train_x_c, train_y_c, test_x_c, test_y_c = dataset.load_data_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([390, 128, 32, 32, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_tensor = train_x_c.permute(0, 1, 4, 2, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([390, 128, 3, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
