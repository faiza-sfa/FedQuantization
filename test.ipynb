{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from load_dataset import Dataset\n",
    "import os\n",
    "\n",
    "import time\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MNIST_PAQ:\n",
    "\tdef __init__(self, filename=\"saved_models\", number_of_clients=1, aggregate_epochs=10, local_epochs=5, precision=7, r=1.0):\n",
    "\t\tself.model = None\n",
    "\t\tself.criterion = torch.nn.CrossEntropyLoss()\n",
    "\t\tself.optimizer = None\n",
    "\t\tself.number_of_clients = number_of_clients\n",
    "\t\tself.aggregate_epochs = aggregate_epochs\n",
    "\t\tself.local_epochs = local_epochs\n",
    "\t\tself.precision = precision\n",
    "\t\tself.r = r\n",
    "\t\tself.filename = filename\n",
    "\n",
    "\tdef define_model(self):\n",
    "\t\tself.model = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv2d(1, 2, kernel_size=5),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Conv2d(2, 4, kernel_size=7),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Flatten(),\n",
    "\t\t\ttorch.nn.Linear(1296, 512),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(512, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 32),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(32, 10),\n",
    "\t\t\ttorch.nn.Softmax(dim=1),\n",
    "\t\t)\t\t\n",
    "\n",
    "\tdef get_weights(self, dtype=np.float32):\n",
    "\t\tprecision = self.precision \n",
    "\t\tweights = []\n",
    "\t\tfor layer in self.model:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tweights.append([np.around(layer.weight.detach().numpy().astype(dtype), decimals=precision), np.around(layer.bias.detach().numpy().astype(dtype), decimals=precision)])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\n",
    "\t\t\t\n",
    "\t\treturn np.array(weights)\n",
    "\n",
    "\tdef set_weights(self, weights):\n",
    "\t\tindex = 0\n",
    "\t\tfor layer_no, layer in enumerate(self.model):\n",
    "\t\t\ttry:\n",
    "\t\t\t\t_ = self.model[layer_no].weight\n",
    "\t\t\t\tself.model[layer_no].weight = torch.nn.Parameter(weights[index][0])\n",
    "\t\t\t\tself.model[layer_no].bias = torch.nn.Parameter(weights[index][1])\n",
    "\t\t\t\tindex += 1\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\tdef average_weights(self, all_weights):\n",
    "\t\tall_weights = np.array(all_weights)\n",
    "\t\tall_weights = np.mean(all_weights, axis=0)\n",
    "\t\tall_weights = [[torch.from_numpy(i[0].astype(np.float32)), torch.from_numpy(i[1].astype(np.float32))] for i in all_weights]\n",
    "\t\treturn all_weights\n",
    "\n",
    "\tdef client_generator(self, train_x, train_y):\n",
    "\t\tnumber_of_clients = self.number_of_clients\n",
    "\t\tsize = train_y.shape[0]//number_of_clients\n",
    "\t\ttrain_x, train_y = train_x.numpy(), train_y.numpy()\n",
    "\t\ttrain_x = np.array([train_x[i:i+size] for i in range(0, len(train_x)-len(train_x)%size, size)])\n",
    "\t\ttrain_y = np.array([train_y[i:i+size] for i in range(0, len(train_y)-len(train_y)%size, size)])\n",
    "\t\ttrain_x = torch.from_numpy(train_x)\n",
    "\t\ttrain_y = torch.from_numpy(train_y)\n",
    "\t\treturn train_x, train_y\n",
    "\n",
    "\tdef single_client(self, dataset, weights, E):\n",
    "\t\tself.define_model()\n",
    "\t\tif weights is not None:\n",
    "\t\t\tself.set_weights(weights)\n",
    "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\t\tfor epoch in range(E):\n",
    "\t\t\trunning_loss = 0\n",
    "\t\t\tfor batch_x, target in zip(dataset['x'], dataset['y']):\n",
    "\t\t\t\toutput = self.model(batch_x)\n",
    "\t\t\t\tloss = self.criterion(output, target)\n",
    "\t\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tself.optimizer.step()\n",
    "\t\t\t\trunning_loss += loss.item()\n",
    "\t\t\trunning_loss /= len(dataset['y'])\n",
    "\t\tweights = self.get_weights()\n",
    "\t\treturn weights, running_loss\n",
    "\n",
    "\tdef test_aggregated_model(self, test_x, test_y, epoch):\n",
    "\t\tacc = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor batch_x, batch_y in zip(test_x, test_y):\n",
    "\t\t\t\ty_pred = self.model(batch_x)\n",
    "\t\t\t\ty_pred = torch.argmax(y_pred, dim=1)\n",
    "\t\t\t\tacc += torch.sum(y_pred == batch_y)/y_pred.shape[0]\n",
    "\t\ttorch.save(self.model, \"./\"+self.filename+\"/model_epoch_\"+str(epoch+1)+\".pt\")\n",
    "\t\treturn (acc/test_x.shape[0])\n",
    "\t\t\t\n",
    "\n",
    "\tdef train_aggregator(self, datasets, datasets_test):\n",
    "\t\tlocal_epochs = self.local_epochs\n",
    "\t\taggregate_epochs = self.aggregate_epochs\n",
    "\t\tos.system('mkdir '+self.filename)\n",
    "\t\tE = local_epochs\n",
    "\t\taggregate_weights = None\n",
    "\t\tfor epoch in range(aggregate_epochs):\n",
    "\t\t\tall_weights = []\n",
    "\t\t\tclient = 0\n",
    "\t\t\trunning_loss = 0\n",
    "\t\t\tselections = np.arange(datasets['x'].shape[0])\n",
    "\t\t\tnp.random.shuffle(selections)\n",
    "\t\t\tselections = selections[:int(self.r*datasets['x'].shape[0])]\n",
    "\t\t\tclients = tqdm(zip(datasets['x'][selections], datasets['y'][selections]), total=selections.shape[0])\n",
    "\t\t\tfor dataset_x, dataset_y in clients:\n",
    "\t\t\t\tdataset = {'x':dataset_x, 'y':dataset_y}\n",
    "\t\t\t\tweights, loss = self.single_client(dataset, aggregate_weights, E)\n",
    "\t\t\t\trunning_loss += loss\n",
    "\t\t\t\tall_weights.append(weights)\n",
    "\t\t\t\tclient += 1\n",
    "\t\t\t\tclients.set_description(str({\"Epoch\":epoch+1,\"Loss\": round(running_loss/client, 5)}))\n",
    "\t\t\t\tclients.refresh()\n",
    "\t\t\taggregate_weights = self.average_weights(all_weights)\n",
    "\t\t\tself.set_weights(aggregate_weights)\n",
    "\t\t\ttest_acc = self.test_aggregated_model(datasets_test['x'], datasets_test['y'], epoch)\n",
    "\t\t\tprint(\"Test Accuracy:\", round(test_acc.item(), 5))\n",
    "\t\t\tclients.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/164 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21348\\2750871235.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(weights)\n",
      "{'Epoch': 1, 'Loss': 2.30127}: 100%|██████████| 164/164 [00:33<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.10314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 2, 'Loss': 2.06227}: 100%|██████████| 164/164 [00:40<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.40439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 3, 'Loss': 1.81644}: 100%|██████████| 164/164 [00:38<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.67542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 4, 'Loss': 1.73126}: 100%|██████████| 164/164 [00:36<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.71642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 5, 'Loss': 1.67489}: 100%|██████████| 164/164 [00:45<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.79046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 6, 'Loss': 1.64659}: 100%|██████████| 164/164 [00:37<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.81476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 7, 'Loss': 1.63231}: 100%|██████████| 164/164 [00:26<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.82343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 8, 'Loss': 1.62473}: 100%|██████████| 164/164 [00:25<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.83056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 9, 'Loss': 1.61952}: 100%|██████████| 164/164 [00:25<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.83698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'Epoch': 10, 'Loss': 1.61211}: 100%|██████████| 164/164 [00:26<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84078\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_clients = 328\n",
    "aggregate_epochs = 10\n",
    "local_epochs = 3\n",
    "r = 0.5\n",
    "filename = \"saved_models\"\n",
    "\n",
    "train_x, train_y, test_x, test_y = Dataset().load_csv()\n",
    "\n",
    "m = MNIST_PAQ(filename=filename, r=r, number_of_clients=number_of_clients, aggregate_epochs=aggregate_epochs, local_epochs=local_epochs)\n",
    "train_x, train_y = m.client_generator(train_x, train_y)\n",
    "m.train_aggregator({'x':train_x, 'y':train_y}, {'x':test_x, 'y':test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Test:\n",
    "\tdef __init__(self, train_x, train_y, test_x, test_y):\n",
    "\t\tself.train_x, self.train_y, self.test_x, self.test_y = train_x, train_y, test_x, test_y\n",
    "\t\tself.criterion = torch.nn.CrossEntropyLoss()\n",
    "\t\t\n",
    "\tdef single_model(self, path):\n",
    "\t\tmodel = torch.load(path)\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\n",
    "\t\t\ttrain_loss, train_acc = 0, 0\n",
    "\n",
    "\t\t\tfor batch_x, target in zip(self.train_x, self.train_y):\n",
    "\t\t\t\toutput = model(batch_x)\n",
    "\t\t\t\tloss = self.criterion(output, target)\n",
    "\t\t\t\toutput = torch.argmax(output, dim=1)\n",
    "\t\t\t\tacc = torch.sum(output == target)/target.shape[0]\n",
    "\t\t\t\tloss = loss.item()\n",
    "\t\t\t\tacc = acc.item()\n",
    "\t\t\t\ttrain_loss += loss\n",
    "\t\t\t\ttrain_acc += acc\n",
    "\n",
    "\t\t\ttrain_loss, train_acc = train_loss/self.train_x.shape[0], train_acc/self.train_x.shape[0]\n",
    "\n",
    "\t\t\ttest_loss, test_acc = 0, 0\n",
    "\n",
    "\t\t\tfor batch_x, target in zip(self.test_x, self.test_y):\n",
    "\t\t\t\toutput = model(batch_x)\n",
    "\t\t\t\tloss = self.criterion(output, target)\n",
    "\t\t\t\toutput = torch.argmax(output, dim=1)\n",
    "\t\t\t\tacc = torch.sum(output == target)/target.shape[0]\n",
    "\t\t\t\tloss = loss.item()\n",
    "\t\t\t\tacc = acc.item()\n",
    "\t\t\t\ttest_loss += loss\n",
    "\t\t\t\ttest_acc += acc\n",
    "\n",
    "\t\ttest_loss, test_acc = test_loss/self.test_x.shape[0], test_acc/self.test_x.shape[0]\n",
    "\n",
    "\t\treturn [train_loss, train_acc, test_loss, test_acc]\n",
    "\n",
    "\tdef analyse_type(self, filename):\n",
    "\t\tmodel_names = os.listdir(filename)\n",
    "\t\tmodels = np.array([filename+i for i in model_names])\n",
    "\t\tmodel_names_index = np.argsort(np.array([int(i[len('model_epoch_'):-3]) for i in model_names]))\n",
    "\t\tmodels = models[model_names_index]\n",
    "\t\tperformance = []\n",
    "\t\tfor model in models:\n",
    "\t\t\tperformance.append(self.single_model(model))\n",
    "\t\tperformance = pd.DataFrame(np.array(performance))\n",
    "\t\tperformance.columns = ['train_loss', 'train_acc', 'test_loss', 'test_acc']\n",
    "\t\tperformance.to_csv('./results/performance_metrics/'+filename[len('./results/models/'):-1]+'.csv', index=False)\n",
    "\n",
    "\t\tperformance = performance.values\n",
    "\t\tbest_index = np.argmin(performance.T[2])\n",
    "\t\treturn performance[best_index]\n",
    "\n",
    "\tdef analyse_all(self):\n",
    "\t\tbar = tqdm(total=3*4*3)\n",
    "\t\tall_best_performances = []\n",
    "\t\twith bar:\n",
    "\t\t\tfor local_epochs in [1, 3, 5]:\n",
    "\t\t\t\tfor r in [0.5, 0.667, 0.833, 1.0]:\n",
    "\t\t\t\t\tfor precision in [5, 6, 7]:\n",
    "\t\t\t\t\t\tfilename = \"./results/models/saved_models_local_epochs_\"+str(local_epochs)+\"_r_\"+str(r).replace('.', '_')+\"_precision_\"+str(precision)+\"/\"\n",
    "\t\t\t\t\t\tbest = self.analyse_type(filename)\n",
    "\t\t\t\t\t\tbest = [local_epochs, r, precision] + [i for i in best]\n",
    "\t\t\t\t\t\tall_best_performances.append(best)\n",
    "\t\t\t\t\t\tbar.update(1)\n",
    "\t\tall_best_performances = pd.DataFrame(np.array(all_best_performances))\n",
    "\t\tall_best_performances.columns = ['local_epochs', 'r', 'precision', 'train_loss', 'train_acc', 'test_loss', 'test_acc']\n",
    "\t\tall_best_performances.to_csv('./results/best_performances.csv', index=False)\n",
    "\n",
    "\tdef image_beautifier(self):\n",
    "\n",
    "\t\timage_names = sorted(['./results/'+i for i in os.listdir('./results/') if '.png' in i])\n",
    "\t\tfor names in [image_names[i:i+4] for i in range(0, 12, 4)]:\n",
    "\t\t\timages = [Image.open(x) for x in names]\n",
    "\t\t\twidths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "\t\t\ttotal_width = sum(widths)\n",
    "\t\t\tmax_height = max(heights)\n",
    "\n",
    "\t\t\tnew_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "\t\t\tx_offset = 0\n",
    "\t\t\tfor im in images:\n",
    "\t\t\t\tnew_im.paste(im, (x_offset,0))\n",
    "\t\t\t\tx_offset += im.size[0]\n",
    "\n",
    "\t\t\tname = names[0][len('./results/'):names[0].index('__')]\n",
    "\t\t\tnew_im.save(name+'_variations.png')\n",
    "\n",
    "\t\t### Resizing for actual use\n",
    "\n",
    "\t\tfor image in [i for i in os.listdir() if '_variations.png' in i]:\n",
    "\t\t\timg = cv2.resize(cv2.imread(image), (1280, 240))\n",
    "\t\t\tcv2.imwrite(image, img)\n",
    "\n",
    "\tdef image(self, performances, names, pic_name):\n",
    "\t\tfor i,name in enumerate(['train_loss', 'train_acc', 'test_loss', 'test_acc']):\n",
    "\t\t\tplt.cla()\n",
    "\t\t\tfor j,performance in enumerate(performances):\n",
    "\t\t\t\tplt.plot(np.arange(10), performance.T[i], label=names[j])\n",
    "\t\t\tplt.legend()\n",
    "\t\t\tif i%2==1:\n",
    "\t\t\t\tplt.ylim([-0.01, 1.01])\n",
    "\t\t\tplt.title(name+' - '+pic_name)\n",
    "\t\t\tplt.savefig('./results/'+pic_name+'__'+name+'_analysis.png')\n",
    "\n",
    "\tdef image_generator(self):\n",
    "\t\tperformance = pd.read_csv('./results/best_performances.csv')\n",
    "\t\tfeatures = performance.columns\n",
    "\t\tperformance = performance.values\n",
    "\t\tbest_index = np.argmin(performance.T[-2])\n",
    "\t\tprint(\"Best Performance By: \", {i:j for i,j in zip(features, performance[best_index])})\n",
    "\n",
    "\t\tlocal_epochs, r, precision = performance[best_index][:3]\n",
    "\t\tlocal_epochs = int(local_epochs)\n",
    "\t\tprecision = int(precision)\n",
    "\n",
    "\t\t### Local Epochs\n",
    "\t\tprint(\"Analysing local_epochs with r and precision fixed to\", r, precision, \"respectively.\")\n",
    "\t\tperformances = []\n",
    "\t\tfor local_epoch in [1, 3, 5]:\n",
    "\t\t\tfilename = \"./results/performance_metrics/saved_models_local_epochs_\"+str(local_epoch)+\"_r_\"+str(r).replace('.', '_')+\"_precision_\"+str(precision)+\".csv\"\n",
    "\t\t\tperformance = pd.read_csv(filename)\n",
    "\t\t\tperformance = performance.values\n",
    "\t\t\tperformances.append(performance)\n",
    "\t\tperformances = np.array(performances)\n",
    "\t\tself.image(performances, names=['local_epochs='+str(i) for i in [1, 3, 5]], pic_name='local_epochs')\n",
    "\n",
    "\t\t### r\n",
    "\t\tprint(\"Analysing local_epochs with local_epochs and precision fixed to\", local_epochs, precision, \"respectively.\")\n",
    "\t\tperformances = []\n",
    "\t\tfor r_id in [0.5, 0.667, 0.833, 1.0]:\n",
    "\t\t\tfilename = \"./results/performance_metrics/saved_models_local_epochs_\"+str(local_epochs)+\"_r_\"+str(r_id).replace('.', '_')+\"_precision_\"+str(precision)+\".csv\"\n",
    "\t\t\tperformance = pd.read_csv(filename)\n",
    "\t\t\tperformance = performance.values\n",
    "\t\t\tperformances.append(performance)\n",
    "\t\tperformances = np.array(performances)\n",
    "\t\tself.image(performances, names=['r='+str(i) for i in [0.5, 0.667, 0.833, 1.0]], pic_name='r')\n",
    "\n",
    "\t\t### r\n",
    "\t\tprint(\"Analysing local_epochs with local_epochs and r fixed to\", local_epochs, r, \"respectively.\")\n",
    "\t\tperformances = []\n",
    "\t\tfor p in [5, 6, 7]:\n",
    "\t\t\tfilename = \"./results/performance_metrics/saved_models_local_epochs_\"+str(local_epochs)+\"_r_\"+str(r).replace('.', '_')+\"_precision_\"+str(p)+\".csv\"\n",
    "\t\t\tperformance = pd.read_csv(filename)\n",
    "\t\t\tperformance = performance.values\n",
    "\t\t\tperformances.append(performance)\n",
    "\t\tperformances = np.array(performances)\n",
    "\t\tself.image(performances, names=['precision='+str(i) for i in [5, 6, 7]], pic_name='precision')\n",
    "\n",
    "\t\tself.image_beautifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './results/models/saved_models_local_epochs_1_r_0_5_precision_5/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train_x, train_y, test_x, test_y \u001b[38;5;241m=\u001b[39m Dataset()\u001b[38;5;241m.\u001b[39mload_csv()\n\u001b[0;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m Test(train_x, train_y, test_x, test_y)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyse_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# test.image_generator()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 66\u001b[0m, in \u001b[0;36mTest.analyse_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m precision \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m]:\n\u001b[0;32m     65\u001b[0m \tfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/models/saved_models_local_epochs_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(local_epochs)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_r_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(r)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_precision_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(precision)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 66\u001b[0m \tbest \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyse_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \tbest \u001b[38;5;241m=\u001b[39m [local_epochs, r, precision] \u001b[38;5;241m+\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m best]\n\u001b[0;32m     68\u001b[0m \tall_best_performances\u001b[38;5;241m.\u001b[39mappend(best)\n",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m, in \u001b[0;36mTest.analyse_type\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyse_type\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 43\u001b[0m \tmodel_names \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \tmodels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([filename\u001b[38;5;241m+\u001b[39mi \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m model_names])\n\u001b[0;32m     45\u001b[0m \tmodel_names_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mint\u001b[39m(i[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_epoch_\u001b[39m\u001b[38;5;124m'\u001b[39m):\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m model_names]))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './results/models/saved_models_local_epochs_1_r_0_5_precision_5/'"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = Dataset().load_csv()\n",
    "test = Test(train_x, train_y, test_x, test_y)\n",
    "test.analyse_all()\n",
    "# test.image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_epochs</th>\n",
       "      <th>r</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.508578</td>\n",
       "      <td>0.954411</td>\n",
       "      <td>1.514189</td>\n",
       "      <td>0.948753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.511121</td>\n",
       "      <td>0.951744</td>\n",
       "      <td>1.515928</td>\n",
       "      <td>0.946746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.512752</td>\n",
       "      <td>0.951553</td>\n",
       "      <td>1.518188</td>\n",
       "      <td>0.946567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.510649</td>\n",
       "      <td>0.952672</td>\n",
       "      <td>1.516274</td>\n",
       "      <td>0.946495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.512172</td>\n",
       "      <td>0.951243</td>\n",
       "      <td>1.518068</td>\n",
       "      <td>0.946173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.515957</td>\n",
       "      <td>0.947147</td>\n",
       "      <td>1.519424</td>\n",
       "      <td>0.944667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.514992</td>\n",
       "      <td>0.949385</td>\n",
       "      <td>1.521292</td>\n",
       "      <td>0.944022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.514191</td>\n",
       "      <td>0.948766</td>\n",
       "      <td>1.519685</td>\n",
       "      <td>0.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.516056</td>\n",
       "      <td>0.947790</td>\n",
       "      <td>1.520447</td>\n",
       "      <td>0.943341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.516362</td>\n",
       "      <td>0.947480</td>\n",
       "      <td>1.522686</td>\n",
       "      <td>0.941335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.515674</td>\n",
       "      <td>0.947528</td>\n",
       "      <td>1.523234</td>\n",
       "      <td>0.940403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.519859</td>\n",
       "      <td>0.944384</td>\n",
       "      <td>1.524126</td>\n",
       "      <td>0.939686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.521976</td>\n",
       "      <td>0.942240</td>\n",
       "      <td>1.525240</td>\n",
       "      <td>0.938288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.521018</td>\n",
       "      <td>0.941311</td>\n",
       "      <td>1.525555</td>\n",
       "      <td>0.937787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.523256</td>\n",
       "      <td>0.938953</td>\n",
       "      <td>1.529110</td>\n",
       "      <td>0.934848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.526521</td>\n",
       "      <td>0.938691</td>\n",
       "      <td>1.532041</td>\n",
       "      <td>0.934203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.526781</td>\n",
       "      <td>0.936881</td>\n",
       "      <td>1.530788</td>\n",
       "      <td>0.934167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.526358</td>\n",
       "      <td>0.936476</td>\n",
       "      <td>1.531463</td>\n",
       "      <td>0.931838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.532927</td>\n",
       "      <td>0.932046</td>\n",
       "      <td>1.538827</td>\n",
       "      <td>0.926032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.533299</td>\n",
       "      <td>0.927615</td>\n",
       "      <td>1.536415</td>\n",
       "      <td>0.925495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.535748</td>\n",
       "      <td>0.926877</td>\n",
       "      <td>1.539819</td>\n",
       "      <td>0.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.539782</td>\n",
       "      <td>0.918779</td>\n",
       "      <td>1.545822</td>\n",
       "      <td>0.913382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.545152</td>\n",
       "      <td>0.904225</td>\n",
       "      <td>1.547673</td>\n",
       "      <td>0.903132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.548609</td>\n",
       "      <td>0.885266</td>\n",
       "      <td>1.552884</td>\n",
       "      <td>0.879981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.575047</td>\n",
       "      <td>0.879883</td>\n",
       "      <td>1.578683</td>\n",
       "      <td>0.876183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.558930</td>\n",
       "      <td>0.834889</td>\n",
       "      <td>1.562574</td>\n",
       "      <td>0.829630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.568372</td>\n",
       "      <td>0.805426</td>\n",
       "      <td>1.569806</td>\n",
       "      <td>0.801964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.614008</td>\n",
       "      <td>0.711223</td>\n",
       "      <td>1.615345</td>\n",
       "      <td>0.715811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.682104</td>\n",
       "      <td>0.646818</td>\n",
       "      <td>1.682835</td>\n",
       "      <td>0.647434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.670572</td>\n",
       "      <td>0.571551</td>\n",
       "      <td>1.672549</td>\n",
       "      <td>0.572427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.728122</td>\n",
       "      <td>0.489591</td>\n",
       "      <td>1.730571</td>\n",
       "      <td>0.490037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.847313</td>\n",
       "      <td>0.208556</td>\n",
       "      <td>1.850548</td>\n",
       "      <td>0.211153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.928221</td>\n",
       "      <td>0.185785</td>\n",
       "      <td>1.929703</td>\n",
       "      <td>0.191908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.963740</td>\n",
       "      <td>0.182808</td>\n",
       "      <td>1.961954</td>\n",
       "      <td>0.188575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.301273</td>\n",
       "      <td>0.111542</td>\n",
       "      <td>2.301137</td>\n",
       "      <td>0.113747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.301338</td>\n",
       "      <td>0.111542</td>\n",
       "      <td>2.301420</td>\n",
       "      <td>0.113747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    local_epochs      r  precision  train_loss  train_acc  test_loss  test_acc\n",
       "23           3.0  1.000        7.0    1.508578   0.954411   1.514189  0.948753\n",
       "27           5.0  0.667        5.0    1.511121   0.951744   1.515928  0.946746\n",
       "22           3.0  1.000        6.0    1.512752   0.951553   1.518188  0.946567\n",
       "32           5.0  0.833        7.0    1.510649   0.952672   1.516274  0.946495\n",
       "18           3.0  0.833        5.0    1.512172   0.951243   1.518068  0.946173\n",
       "25           5.0  0.500        6.0    1.515957   0.947147   1.519424  0.944667\n",
       "19           3.0  0.833        6.0    1.514992   0.949385   1.521292  0.944022\n",
       "34           5.0  1.000        6.0    1.514191   0.948766   1.519685  0.943700\n",
       "26           5.0  0.500        7.0    1.516056   0.947790   1.520447  0.943341\n",
       "21           3.0  1.000        5.0    1.516362   0.947480   1.522686  0.941335\n",
       "30           5.0  0.833        5.0    1.515674   0.947528   1.523234  0.940403\n",
       "28           5.0  0.667        6.0    1.519859   0.944384   1.524126  0.939686\n",
       "20           3.0  0.833        7.0    1.521976   0.942240   1.525240  0.938288\n",
       "33           5.0  1.000        5.0    1.521018   0.941311   1.525555  0.937787\n",
       "15           3.0  0.667        5.0    1.523256   0.938953   1.529110  0.934848\n",
       "17           3.0  0.667        7.0    1.526521   0.938691   1.532041  0.934203\n",
       "16           3.0  0.667        6.0    1.526781   0.936881   1.530788  0.934167\n",
       "24           5.0  0.500        5.0    1.526358   0.936476   1.531463  0.931838\n",
       "29           5.0  0.667        7.0    1.532927   0.932046   1.538827  0.926032\n",
       "12           3.0  0.500        5.0    1.533299   0.927615   1.536415  0.925495\n",
       "14           3.0  0.500        7.0    1.535748   0.926877   1.539819  0.923810\n",
       "13           3.0  0.500        6.0    1.539782   0.918779   1.545822  0.913382\n",
       "7            1.0  0.833        6.0    1.545152   0.904225   1.547673  0.903132\n",
       "10           1.0  1.000        6.0    1.548609   0.885266   1.552884  0.879981\n",
       "31           5.0  0.833        6.0    1.575047   0.879883   1.578683  0.876183\n",
       "8            1.0  0.833        7.0    1.558930   0.834889   1.562574  0.829630\n",
       "6            1.0  0.833        5.0    1.568372   0.805426   1.569806  0.801964\n",
       "4            1.0  0.667        6.0    1.614008   0.711223   1.615345  0.715811\n",
       "1            1.0  0.500        6.0    1.682104   0.646818   1.682835  0.647434\n",
       "5            1.0  0.667        7.0    1.670572   0.571551   1.672549  0.572427\n",
       "0            1.0  0.500        5.0    1.728122   0.489591   1.730571  0.490037\n",
       "11           1.0  1.000        7.0    1.847313   0.208556   1.850548  0.211153\n",
       "2            1.0  0.500        7.0    1.928221   0.185785   1.929703  0.191908\n",
       "3            1.0  0.667        5.0    1.963740   0.182808   1.961954  0.188575\n",
       "9            1.0  1.000        5.0    2.301273   0.111542   2.301137  0.113747\n",
       "35           5.0  1.000        7.0    2.301338   0.111542   2.301420  0.113747"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(rf'E:\\MS_Thesis\\Hierarchical_quantization\\FedPAQ-MNIST-implemenation-main\\results\\best_performances.csv')\n",
    "data.sort_values(by='test_acc',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
